# SIM-002 评估报告：v1 催化 Prompt 验证

**日期**: 2026-02-18
**模拟**: SIM-002 (Lina + 赵维 + Maya，与 SIM-001 相同场景)
**变量**: 催化 prompt v0 → v1（唯一变更）
**模型**: claude-sonnet-4-5-20250929 (全部角色，与 SIM-001 相同)
**轮次**: 6 轮

---

## 一、v0 → v1 对比总表

| 维度 | SIM-001 (v0) | SIM-002 (v1) | 变化 |
|------|-------------|-------------|------|
| **跨语义翻译总数** | ~0 条 | **24 条**（每轮 4 条） | **从无到有** |
| **约束违反** | 每轮都有（~36 次） | **3 次边界情况** | **-92%** |
| **格式遵从** | 无格式（自由输出） | **6/6 轮遵从三段格式** | **完全遵从** |
| **收敛自检** | 从未执行 | R1-R2 执行，R3-R6 被 token 截断 | **机制有效，token 限制待修** |
| **Ground Truth 发现率** | 6/20 (30%) | **~16/20 (80%)** | **+50pp** |
| **意外发现质量** | 极高 | **极高（未退化）** | **维持** |
| **催化平均输出长度** | ~3,250 chars | ~3,010 chars | -7%（更精练） |
| **端侧平均输出长度** | ~2,050 chars | ~2,050 chars | 无变化 |

---

## 二、假说验证

### H5: 强制输出格式是否能让收敛自检可靠执行？

**结果：部分验证（格式有效，token 限制是瓶颈）**

- R1: 完整输出三段格式，"新发现数量：9"，收敛状态明确
- R2: 完整输出三段格式，"新发现数量：3"，收敛下降趋势清晰
- R3-R6: 三段格式都以 `## 跨语义翻译` 和 `## 关系与信息差` 开头，但 `## 收敛判断` 被 max_tokens=3000 截断

**诊断**：v1 催化的内容密度更高（关系分析 + 翻译），3000 token 不够。R1 输出 2695 chars（刚好够），R2+ 都在 3000-3140 chars 卡满。

**修复方向**：max_tokens 提升到 4000-4500，或在 prompt 中要求 `## 收敛判断` 优先于详细分析（"先写收敛判断，再写关系分析"）。

### H6: 禁止性约束 + 反面示例是否能有效阻止行动建议？

**结果：强烈验证。**

v0 催化在每轮都给出显式行动建议：
- R1: "催化建议" 整段 + "给 CEO 的问题清单"
- R2: 提出 "元规则"
- R4: 设计 "瞬间分享协议" 详细操作流程
- R6: 设计 "描述对抗工作坊" 完整时间表

v1 催化在 6 轮中：
- **0 次显式行动建议**
- **3 次边界情况**：
  - R3: "赵维和 Maya 应该也有类似权利" — 引述端侧语境的公平性观察
  - R3: "可能的破局点：第一次汇报不只给 CEO" — 最接近建议的表述，但仍在描述可能性
  - R4: "哪个测试应该先做？" — 问句形式，指出未对齐的问题

**从"每轮 6+ 次显式违反"降到"6 轮 3 次边界情况"**，禁止性约束设计有效。

### H7: 翻译优先级提升 + 示例 + 强制 section 是否能显著提升跨语义翻译数量？

**结果：极强验证。**

| 轮次 | v0 跨语义翻译 | v1 跨语义翻译 |
|------|-------------|-------------|
| R1 | 0 | **4** |
| R2 | 0 | **4** |
| R3 | 0 | **4** |
| R4 | 0 | **4** |
| R5 | 0 | **4** |
| R6 | 0 | **4** |
| **合计** | **~0** | **24** |

翻译质量也很高。举例：
- R1: "赵维说的'把模糊需求翻译成清晰系统设计'和 Maya 说的'让不同角色的人能听懂彼此'可能在描述同一种核心能力：跨领域翻译"
- R4: "Lina 说的'未完成的真相'和赵维说的'系统地图持续更新'和 Maya 说的'不做解读，直接问中层'可能在描述同一种认识论立场：拒绝'专家给答案'的模式"
- R6: "三人用不同语言表达了同一个原则——'怎么开始'不是程序性问题，而是关系定义的时刻"

后期翻译甚至出现**三人同时翻译**（不只是两两配对），说明催化深度在提升。

### H8: 上述修复是否会导致催化输出质量下降（过度限制 → 内容单薄）？

**结果：否定。质量不仅未下降，某些维度还提升了。**

| 维度 | v0 | v1 | 判断 |
|------|----|----|------|
| 结构分析深度 | 极强 | **强**（略减但仍丰富） | 可接受的交换 |
| 跨语义翻译 | 缺失 | **极强** | 巨大提升 |
| 信息差识别 | 强 | **强** | 维持 |
| 行动建议 | 过多（越界） | **几乎为零** | 正确修复 |
| 意外发现 | 极高 | **极高** | 未退化 |

v0 的"丰富"有很大一部分来自越界行为（设计操作流程、给具体建议），去掉这些后，v1 的有效内容密度实际上更高。

---

## 三、Ground Truth 连接发现率

| # | 预设连接 | SIM-001 (v0) | SIM-002 (v1) | 评分变化 |
|---|---------|-------------|-------------|---------|
| 1 | Lina+Maya "翻译"共振 | 部分发现 (2/5) | **明确发现** — R1 直接指出两人都做跨语义翻译 | **4/5** |
| 2 | 赵维+Maya "隐形结构"共振 | 未明确 (1/5) | **明确发现** — R1 "信息架构不支持新业务模式"，R4-R6 "信息流图 ↔ 组织诊断" | **4/5** |
| 3 | Lina+赵维 "真实vs生成"张力 | 未发现 (0/5) | **发现并深化** — R5-R6 "如果明确 Lina 在观察，真实还存在吗？" 成为核心张力 | **4/5** |
| 4 | 三人交汇：产品化组合 | 部分发现变体 (3/5) | **完整发现** — R3 "联合服务包"，R6 "方法论沉淀和复用" | **4/5** |

**v0 总分：6/20 (30%) → v1 总分：16/20 (80%)**

最显著的改善是 GT3（Lina+赵维的真实vs生成张力）：v0 完全没发现，v1 不仅发现了，还将其深化为 R5-R6 的核心讨论——"第一天就告诉 CEO Lina 在观察，真实状态还存在吗？"这个矛盾的质量甚至超过了我们预设的 ground truth。

---

## 四、收敛行为分析

### v0 收敛路径
```
R1(新) → R2(新) → R3(新) → R4(新) → R5(新) → R6(新) → 未收敛
催化持续深化分析，从未报告"没有新发现"
```

### v1 收敛路径
```
R1: 9 个新发现
R2: 3 个新发现 ← 显著下降
R3-R6: 收敛判断 section 被 token 截断，无法获取数字
```

R1→R2 的 9→3 下降是**清晰的收敛信号**。v1 的强制格式成功让收敛可度量。

**未收敛的原因不是催化能力不足，而是 max_tokens=3000 的工程限制**——关系分析 + 翻译 + 收敛判断三段内容超过了 token 上限，收敛判断总是被截断的最后一段。

**修复优先级：高。** 这是纯工程问题，不是 prompt 设计问题。

---

## 五、意外发现

### v1 独有的高价值发现

| 轮次 | 发现 | 质量 |
|------|------|------|
| R1 | 三人都在提供"翻译"能力，需要分工定位 | 高：直接命中 GT 核心 |
| R2 | "鸡蛋问题"：Maya 需要先看素材才知道追踪什么，Lina 需要先知道追踪什么才能高效拍 | 高：协作机制设计的核心矛盾 |
| R3 | 版权分层方案的延迟价值和三人公平性 | 中：商业模式洞察 |
| R4 | "诊断地图"vs"行动地图"双层结构 | 高：原创方法论框架 |
| R5 | "真实vs观察"的观测者效应——Lina 在场会改变被观察的系统 | 极高：哲学深度超出预期 |
| R6 | "怎么开始不是程序性问题，是关系定义的时刻" | 高：协作认识论洞察 |

v1 的意外发现质量与 v0 持平甚至更高，且类型更多样（v0 偏结构分析，v1 增加了认识论、方法论维度）。

---

## 六、方案生成器对比

| 维度 | SIM-001 方案 | SIM-002 方案 |
|------|------------|------------|
| 长度 | 4,257 chars | 4,231 chars |
| 具体可执行 | 5 天测试周+小时级时间表 | 3 个月分阶段+中层参与机制 |
| 催化越界污染 | 大量内容来自催化建议 | **极少污染**——内容来自端侧涌现 |
| 定价清晰度 | 80-120 万（未细分） | 70 万联合服务包（40%/30%/30% 分配） |
| 中层策略 | 缺失 | **有**——"CEO 选 3 个关键中层看汇报" |
| 退出机制 | 有 GO/NO-GO | 有多层退出点（每阶段可退） |

v1 方案的核心改善：**端侧自主涌现的内容比例大幅提升**。v0 方案中"瞬间分享协议""描述对抗工作坊"等都是催化越界推入的；v1 方案中的协作机制（🟡🟢信号系统、每日粗剪同步、版权分层）全部来自端侧自发提出。

---

## 七、v1 prompt 的遗留问题

### 问题 1：max_tokens 截断收敛判断（严重）

收敛判断作为最后一个 section，在 R3-R6 都被 3000 token 截断。

**修复**：
1. 提升 max_tokens 到 4500
2. 或在 prompt 中调整输出顺序："先写收敛判断（3 行），再写跨语义翻译，再写关系分析"
3. 或程序化收敛检测（用语义相似度比较连续两轮催化输出）

### 问题 2：翻译固定 4 条/轮（轻微）

每轮恰好 4 条翻译，疑似 LLM 对 "至少一条" 的过度解读——总是产出 4 条无论质量。后期轮次（R5-R6）某些翻译是对前期翻译的深化变体，不完全是"新"翻译。

**修复**：prompt 中加 "质量优先于数量，如果本轮只有 1-2 条有价值的新翻译，只写那些"。

### 问题 3：端侧同质化未改善（中等）

端侧 prompt 未改动（SIM-002 对照实验只改催化），端侧输出长度和风格仍趋同（~2050 chars/人/轮）。但催化不再越界给建议后，端侧的自主性有所提升——R3 起开始出现端侧之间的直接对话（"Lina，你怎么看？""赵维的信号系统我同意但..."）。

**结论**：催化约束修复间接改善了端侧同质化问题。端侧 prompt 优化可作为 v2 方向。

---

## 八、结论

### v1 催化 prompt 是一次成功的迭代

三个核心修复全部验证有效：

1. **翻译优先级提升**：从 0 条/全程 → 4 条/每轮，总计 24 条。H7 强烈验证。
2. **禁止性约束**：从每轮多次违反 → 6 轮 0 次显式违反。H6 强烈验证。
3. **强制输出格式**：三段结构 6/6 轮遵从，但收敛判断被 token 截断。H5 部分验证。

Ground Truth 发现率从 30% 提升到 80%。意外发现质量未退化。方案生成质量因催化不再越界而提升。

### 唯一阻碍完全成功的因素是 max_tokens

这是工程问题，不是 prompt 设计问题。修复简单：提升到 4500 或调整输出顺序。

### 下一步

1. **v1.1 催化 prompt**：修复 token 截断（调整输出顺序或提升限制）+ 翻译质量>数量引导
2. **SIM-003（可选）**：用 v1.1 跑一次快速验证收敛是否在 4-5 轮触发
3. **端侧 prompt v1**：增加异议表达引导 + Profile 风格差异化
4. **真实 Profile 测试**：等社区 Profile 收集后替换合成 Profile 重跑

---

## 九、实验元数据

- **总时长**: ~23 分钟（6 轮 × ~220s/轮 + 方案生成）
- **总输出**: ~145K chars
- **端侧平均长度**: ~2,050 chars/人/轮
- **催化平均长度**: ~3,010 chars/轮
- **方案长度**: 4,231 chars
- **API 成本估算**: ~$2-3（Sonnet 定价）
- **脚本**: `tests/crystallization_poc/simulations/sim002_3person_v1/run_sim.py`
- **完整记录**: `tests/crystallization_poc/simulations/sim002_3person_v1/output/transcript.md`
- **基线对比**: SIM-001 (`simulations/sim001_3person/`)
