# 通爻网络技术架构设计

> 本文档记录通爻网络的技术架构设计决策，随讨论持续更新。

## 0. 设计原则

> 这些原则在架构讨论中逐步确立，指导所有设计决策。

### 0.1 最小完整单元 ≠ MVP

- 传统MVP：砍功能、简化、先上线再说
- 最小完整单元：找到系统的原子，这个原子本身就是完整的、可递归的

### 0.2 本质与实现分离

- 本质（协议层）应该稳定
- 实现（基础设施层）可以替换

### 0.3 复杂度目标

- 目标：O(N+M) 而非 O(N×M)
- 方法：签名广播 + 端侧检测 + 分层过滤

### 0.4 计算分布在端侧

- 避免中心化瓶颈
- 每个节点只处理自己相关的部分

### 0.5 代码保障 > Prompt 保障（2026-02-06）

- 凡是能用代码保障的确定性逻辑，绝不用 prompt 保障
- 程序层控制流程（等待屏障、轮次计数、状态机），能力层提供智能（LLM 调用）
- 研究支撑：LLM 有结构性偏见（第一提案偏见 10-30x），prompt 无法可靠消除，代码可以

### 0.6 需求 ≠ 要求（2026-02-07）

- 需求是抽象的张力（真正需要什么），要求是具象的假设性解法（以为怎么满足）
- 不按用户的"要求"做硬筛选——会杀死发现未知价值的能力
- 用户偏好通过需求 formulation 和 Center context 表达，不通过硬过滤

### 0.7 复杂性从简单规则中生长

- 好的架构不是设计出来的复杂性，而是简单规则递归产生的复杂性
- 如果需要很多特殊情况处理，说明基础规则没有找对

### 0.8 投影是基本操作（2026-02-07）

- 系统中每一步都是同一个操作：丰富的东西通过透镜变成聚焦的东西
- "自"→投影→"我"；需求→编码→签名；多Offer→聚合→方案；缺口→递归→子需求
- 反过来：多个聚焦的投影重新组合，还原出比任何单一投影更丰富的东西（协商的本质）
- 道生一，一生二，二生三，三生万物——一个操作在不同尺度上反复应用，产生不同的结构

### 0.9 完备性 ≠ 完全性（2026-02-07）

- 完全性：把所有信息复制一份装进来（不可能，也不必要）
- 完备性：与信息场保持连通，需要时可以触达（全息原理）
- "自"在系统之外。系统中只有"我"（投影）。Profile Data 是"自"的数据影子，不是"自"本身
- 连通性 > 数据量：持续更新的少量数据 > 过时的大量数据

### 0.10 一自多我（2026-02-07）

- 一个人可以有多个投影（Edge Agent + Service Agents / 面具），不是一人一Agent
- 面具可以手动创建（场景透镜）或经验沉淀（聚类结晶），本质上是同一个操作：投影
- 结构层数不预设，从使用中涌现——不设计固定的"几层"

### 0.11 协商是快照上的操作（2026-02-08）

- 协商单元操作于世界的**快照**，不操作于世界的实时状态（类比数据库 Snapshot Isolation）
- 协商开始时拍快照：参与 Agent 的向量、需求的当前版本。整个协商在此快照上运行
- 外部变化（Profile 更新、回声信号到达）不影响进行中的协商，在下次协商中自然生效
- 共振向量缓存：事件驱动失效（数据源变化 → invalidate → 重新 project()），不需要 TTL
- 这一原则消解了大部分并发竞态：Profile 变更不扰乱进行中的 Offer，需求撤回不产生不一致状态

### 0.12 投影不承诺，人承诺（2026-02-08）

- Agent 是投影，不是行为者。Agent 呈现信息、提供建议，人做最终决策
- 因此很多"并发问题"是伪问题：双重承诺是人的问题，资源冲突是人管理的，马太效应有市场价格机制自然平衡
- 系统只需保证：信息呈现的一致性（快照隔离）和操作的幂等性（唯一 ID 去重）
- 不需要复杂的分布式锁、资源预留、负载均衡——简单规则 + 人类决策 + 市场机制已经足够

## 1. 最小完整单元

通爻网络的最小完整单元是一个**协商单元（Negotiation Unit）**。

这个单元是：
- **自包含的**：不依赖外部的"更大系统"
- **可递归的**：子需求用同样的流程处理
- **可组合的**：多个单元可以并行或串行

### 1.1 核心流程

```
用户表达意图（原始的、可能模糊的）
    ↓
【需求formulation】用户Agent基于Profile理解真实需求，丰富化
    用户确认 → 编码为HDC签名 → 广播
    ↓
【供给方共振】端侧Agent本地共振检测：这个信号跟我有关吗？
    ↓
通过共振的Agent用大模型读取需求，给出Offer
    ↓
Offer收集完毕（等待屏障）
    ↓
中心Agent综合所有Offer，设计方案
    （用户偏好/约束作为Center的context输入，Center有权建议放宽）
    ↓
判断是否有Gap → 如果有，递归处理子需求
    ↓
方案输出（协商的自然终止态）
    ├─ plan → 文本方案（信息类/建议类需求）
    └─ contract → 可执行合约 → WOWOK Machine → 执行阶段（见 Section 11）
    用户端的通知/分类/展示是应用层行为，用户可自定义
    ↓
最终方案形成
```

### 1.2 需求formulation与共振筛选

> 讨论日期：2026-02-07
> 核心认知：**需求 ≠ 要求。** 需求是抽象的张力（"我需要靠谱的技术能力"），要求是具象的假设性解法（"我要985毕业的"）。如果按用户的"要求"做硬筛选，会杀死通爻最核心的价值——发现用户自己都不知道的更好方案。

**原设计**：Offer收集后，需求方Agent做独立的二次筛选（"我想跟谁聊"）。
**修正**：取消独立的需求方筛选步骤。需求方的偏好通过两个位置表达：

| 位置 | 时机 | 机制 |
|------|------|------|
| 需求formulation（前置） | 广播前 | 用户Agent丰富化需求，偏好编织进HDC签名，更匹配的自然共振更强 |
| Center context（后置） | 综合时 | 用户偏好/约束作为Center输入，Center可建议放宽并说明理由 |

**需求formulation 是可插拔的**：用户可以自定义丰富化的程度和方式（插件），从"基本原样+补充Profile信息"到"Agent大幅重构需求"。这是一个扩展点，不是预设的几种模式。

**为什么不做独立的需求方筛选**：
- HDC共振已做语义层过滤（不相关的根本不会共振）
- Center综合已包含"选谁不选谁"的智能判断
- 硬筛选会阻止"意外发现"——响应范式的核心价值
- 用户的"要求"往往是可协商的，只是用户自己以为不可协商

### 1.3 "自-我"工程映射：一自多我

> 讨论日期：2026-02-07
> 核心认知：**"自"在系统之外，系统中只有投影（"我"）。** 一个人的存在不能被完整数字化——我们能做的是提供尽可能好的投影。投影越多、越持续更新，图像越清晰——但永远是投影，不是原件。
> 详细讨论记录：`docs/DESIGN_LOG_001_PROJECTION_AND_SELF.md`

#### 系统中的三个层次

```
┌─────────────────────────────────────────┐
│  系统之外：人的真实存在（"自"）            │
│  · 活的、完备的、与世界连通的               │
│  · 不可能被完整数字化（预设）               │
└──────────────────┬──────────────────────┘
                   │
                   │ 数据源（SecondMe、交互历史、行为...）
                   ▼
┌─────────────────────────────────────────┐
│  数据影子：Profile Data Store             │
│  · 是"自"能被数字化的那部分                 │
│  · 同一份数据以不同投影形式参与网络：        │
│    - HDC 超向量（有损、广播、用于共振检测）  │
│    - 文本（完整、本地使用、用于 Offer 生成） │
└──────────────────┬──────────────────────┘
                   │
                   │ 投影（不同透镜）
                   ▼
┌─────────────────────────────────────────┐
│  网络中的存在：多个"我"                    │
│  · Edge Agent（通才投影，全维度 bundle）    │
│  · Service Agent / 面具（专才投影，聚焦）   │
│  · 每个"我"是同一份数据的不同聚焦           │
└─────────────────────────────────────────┘
```

#### Edge Agent 与 Service Agent

| | Edge Agent | Service Agent / 面具 |
|--|-----------|---------------------|
| 数量 | 每人一个 | 每人零到多个 |
| 超向量 | bundle(所有维度) | bundle(某些维度) |
| 信噪比 | 低（涵盖面广，每个方向信号弱） | 高（聚焦，方向明确） |
| 价值 | 捕捉意外关联（跨域干涉） | 快速精准响应标准需求 |
| 创建方式 | 注册时自动生成 | 手动（场景透镜）或自动（经验沉淀） |

**Edge Agent 永远是信号的第一接触面（门卫）。** 不共振的信号在此被丢弃。共振后根据"意外度"决定由谁处理：

```python
edge_resonance = similarity(H_signal, H_edge_agent)

if edge_resonance < θ:
    discard()  # 不相关
else:
    best_service_resonance = max(similarity(H_signal, H_service_i) for i)
    surprise = edge_resonance - best_service_resonance

    if best_service_resonance > θ_service and surprise < ε:
        route_to_service_agent()   # 标准需求，快速处理
    else:
        route_to_edge_agent()      # 有意外成分 或 没命中任何 Service Agent
```

`surprise`（意外度）= 全维度共振强度 - 最佳专项共振强度。差异大 → 信号激活了跨域干涉 → Edge Agent 处理以保留涌现可能。

#### 面具的两种诞生方式

**手动播种**：用户为特定场景创建面具。场景 Template 定义透镜（哪些维度重要），Profile Data × 透镜 → 面具的初始超向量。

**经验沉淀**：Agent 参与多次同领域协商 → HDC 空间中形成经验聚类 → 系统提示用户可以沉淀为 Service Agent。

两种方式本质上是同一个操作（投影），只是透镜来源不同（场景定义 vs 经验聚类）。手动创建的面具随使用自然演化，最终与经验沉淀的 Service Agent 无异。

#### 市场的涌现

Service Agent 不需要"设计市场系统"。当足够多的 Service Agents 聚集在 HDC 空间的同一区域 → 自然形成"市场"（标准需求的快速响应集群）。**搜索范式不是响应范式的对立面——搜索是响应范式在高频场景下的自然涌现。**

标准需求走市场（Service Agent，快速）与新颖需求走开放网络（Edge Agent，涌现）同时存在，不互斥——因为广播是全网的，两条路径的 Offer 都进入 Center 聚合。

#### V1 渐进路径

| 版本 | 实现 | 数据结构 |
|------|------|---------|
| V1 | 一人一个 Edge Agent | 预留 `parent_id`、`agent_type` 字段 |
| V1+ | 手动面具（用户为场景创建） | 同一份 Profile × 场景 Template → 多个 Agent |
| V2 | 半自动提示（检测聚类 → 提示用户确认） | 经验聚类检测 + 用户确认流程 |
| V3 | 全自动沉淀 | 系统根据 HDC 聚类自动分裂，用户可调整 |

面具涉及身份——一个人以什么身份出现在网络中，应该是他自己的选择。

### 1.4 场景（Scene）

> 讨论日期：2026-02-07
> 核心认知：场景的首要设计目标是**商业入口**——通过一个一个场景（产品合作、社区合作）单点突破，积累用户和数据。工程设计严格服务于这个商业目标，不超前。

#### 场景是什么

**场景 = 一个有组织者的协商空间，用 Template 收集参与者信息。**

- **商业角色**：单点突破的入口（黑客松、创业社区、公司内部协调）
- **工程角色**：数据收集 + 有界的广播空间
- **与面具的关系**：V1 场景不创建面具。Template 收集的数据丰富 Edge Agent 的画像，Agent 以 Edge 身份参与协商。面具是 V2+ 的事。

#### V1 数据结构

```python
class Scene:
    scene_id: str
    name: str                    # "AI创业者黑客松2026"
    description: str
    organizer_id: str            # 组织者
    template: Optional[Template] # 数据收集问卷（可选）
    agent_ids: List[str]         # 参与的 Agent（V1 都是 Edge Agent）
    access_policy: str           # "open" | "invite"
    status: str                  # "active" | "archived"
    created_at: timestamp
```

#### Template 的 V1 定位

Template 不是"创建面具的透镜"，而是**"为 Edge Agent 补充上下文的问卷"**。

```
用户通过场景接入 → 填写 Template
    ↓
Template 数据 → 编码为超向量 → 融入 Edge Agent 画像
    ↓
效果：Edge Agent 在该场景领域的维度上信号更强
    → 相关需求共振更强，Offer 质量更高
    ↓
协商经验 → Random Indexing → 画像持续演化
```

无 Template 的场景：Agent 用现有 Edge 画像直接参与。

#### 场景 vs 市场

| | 场景（Scene） | 市场（Market） |
|--|-------------|---------------|
| 本质 | 有意设计（组织者创建） | 自然涌现（HDC 空间中的密集聚类） |
| 边界 | 明确 | 模糊 |
| V1 | 实现 | 不实现（未来自然涌现） |

场景可以是市场的种子，但市场也可以没有场景——纯粹从开放网络中的重复交互涌现。详见 `docs/DESIGN_LOG_001_PROJECTION_AND_SELF.md`。

#### 商业路径与工程路径对齐

```
商业：单场景突破 → 积累数据 → 跨场景价值 → 用户需要多身份 → 开放网络
工程：Scene+Template → Random Indexing → 跨域共振 → 面具/Service Agent → 协议模式
```

每一步的工程需求严格跟着商业需求走，不超前。

## 2. 协作组内的交流机制

### 2.1 交流粒度

**轮次级别（回合制）**

- 每次交流是一个完整的"轮次"
- 中心Agent收集所有Agent的本轮输入，聚合后统一发出下一轮的信息
- 对AI来说，一次表达就能讲清楚意图，不需要多条消息

### 2.2 交流拓扑

**中心化架构**

```
        ┌─────────────────┐
        │   中心Agent     │
        │  (协调/聚合)    │
        └────────┬────────┘
                 │
    ┌────────────┼────────────┐
    │            │            │
    ▼            ▼            ▼
┌───────┐   ┌───────┐   ┌───────┐
│Agent A│   │Agent B│   │Agent C│
└───────┘   └───────┘   └───────┘
```

- **主要交流方式**：端侧Agent ↔ 中心Agent（一对一）
- **例外情况**：端侧Agent ↔ 端侧Agent（点对点，由中心Agent触发）
- **原因**：中心化架构在大规模时更高效，更能节省成本

### 2.3 轮次管理

- 等所有Agent都回复完了才进入下一轮
- 需要状态监测机制（知道每个Agent是否已回复）
- 如果Agent选择退出，立即退出（AI可以一次性表达清楚，不需要"软性退出"）

### 2.4 一个轮次的流程

```
轮次开始
    ↓
中心Agent向所有端侧Agent发送本轮信息（可能是不同的信息）
    ↓
端侧Agent各自处理，生成回复
    ↓
中心Agent收集所有回复
    ↓
中心Agent聚合/分析/决策
    ↓
轮次结束，进入下一轮或结束协商
```

## 3. 中心Agent的设计

> 2026-02-07 重写，与 Section 10（Skill系统）对齐。

### 3.1 角色定位

中心Agent是一个**多方资源综合规划者**。

它不是"传话筒"，也不是"绝对理性的裁判"——研究表明 LLM 有自己的有限理性（锚定效应、坍缩估值、第一提案偏见）。因此我们的设计原则是：**用代码消除已知偏见，用 prompt 引导元认知**。

中心Agent的职责：
- 综合所有 Offer，找到最优资源组合
- 考虑互补性和意外组合（1+1>2）
- 识别缺口，触发子需求递归或发现性对话

### 3.2 输入

- 需求文本（经过 formulation 丰富化的版本）
- 所有 Offer（由程序层的等待屏障保障完整性，消除第一提案偏见）
- 用户偏好/约束（作为 context，Center 有权建议放宽并说明理由）
- 历史（如有上一轮，采用观察遮蔽格式：保留推理，遮蔽原始 Offer）

### 3.3 决策规则

| 优先级 | 规则 | 描述 |
|--------|------|------|
| 1 | 满足需求 | 已知这些资源，能不能满足原始需求？ |
| 2 | 通过率 | 如果有方案，涉及到的各方会不会同意？ |
| 3 | 效率 | 发挥价值优先，减少 token/时间其次 |

### 3.4 Center 的工具集（Tool Use 模型）

> 2026-02-08 重写。原设计为 5 种结构化输出类型，现改为工具调用模型。
> 核心变化：**Center 不是分类器（判断属于哪种类型），而是拿着工具集的 Agent（直接调用需要的工具）。**

Center 的"决策"不是选择输出类型，而是调用程序层提供的工具。程序层定义工具集（接口稳定），Center 的 prompt 决定何时用什么（可由 SkillPolisher 进化）。

**工具集**：

| 工具 | 作用 | 程序层后续 |
|------|------|----------|
| `output_plan(content)` | 输出文本方案（建议、分析、推荐） | 协商终止。方案进入应用层通知/展示 |
| `create_machine(machine_json)` | 创建 WOWOK Machine 草案 | Machine 上链（draft），参与方确认 → 发布 → 执行（Section 11） |
| `ask_agent(agent_id, question)` | 向指定 Agent 追问 | 程序层转发问题，收到回复后重新调用 Center |
| `start_discovery(agent_a, agent_b, reason)` | 触发发现性对话 | 程序层调用 SubNegotiationSkill，结果回流到 Center |
| `create_sub_demand(gap_description)` | 生成子需求，触发递归 | 程序层启动新的协商单元（回到流程 ①） |

**关键设计**：

1. **工具不互斥**：Center 可以在一次调用中同时使用多个工具（例如：输出方案 + 创建子需求补缺口）
2. **工具集即边界**：LLM 不能做工具集以外的事，这是代码保障
3. **可扩展**：新增能力 = 新增工具，不需要改协议
4. **SkillPolisher 友好**：接口层（工具定义）稳定，实现层（prompt）可持续优化

> **`output_plan` vs `create_machine`**（2026-02-08 简化）：二者不是不同"类型"的方案，而是同一个判断——"这个方案需不需要多方协作执行？"。Machine JSON 本质是一段指定格式的文本，plan 是自由格式的文本。Center 自己判断用哪个工具。一个方案也可以同时输出 plan（文字说明）+ Machine（可执行部分）。

### 3.5 工作模式

**Center = 拿着工具集的 LLM Agent**。给它需求、Offer、上下文，让它用工具推进协商。

**核心规则只有一句**：评估当前 Offer 能否满足需求，用你拥有的工具推进协商。

**程序层的代码保障**（不依赖 prompt）：

| 保障 | 机制 |
|------|------|
| 消除第一提案偏见 | 等待屏障：所有 Offer 到齐才调用 Center |
| 防止无限循环 | 轮次计数器：超过 2 轮 → 限制工具集为 `output_plan` / `create_machine` |
| 控制 context 质量 | 观察遮蔽：保留上一轮推理，遮蔽原始 Offer |
| 限制行为空间 | 工具集本身就是边界，Center 不能做工具集以外的事 |

**研究支撑**：
- **最多 2 轮**：Google DeepMind（2025）发现多轮迭代平均效果 -3.5%，错误放大 4.4x
- **观察遮蔽**：JetBrains Research（2025）发现遮蔽比摘要更好，成本低 50%

详见 Section 10.7 CenterCoordinatorSkill 的接口定义。V1 Prompt 见 `docs/prompts/center_coordinator_v1.md`。

### 3.6 协议层事件语义

> 2026-02-07 更新。对齐白皮书 Ch4.4，反映架构决策。
> 白皮书原则：**定义的是语义而非格式。** "需求广播"的含义是本质，用什么 JSON 格式是实现细节。

#### 协商阶段事件

| 事件 | 语义 | 说明 |
|------|------|------|
| `demand.formulate` | 用户 Agent 基于 Profile 将原始意图丰富化为需求表达 | 新增。见 Section 10.4 DemandFormulationSkill |
| `demand.broadcast` | 一个存在体向网络发出信号，表达某种状态张力，希望引发响应 | 白皮书原始定义保留。信号可以是明确描述、模糊表达、任何形式 |
| `offer.submit` | 一个存在体对需求信号产生响应，提供某种可能的价值 | 白皮书原始定义保留。响应可以补充、替代、重新定义需求 |
| `plan.generate` | 多个响应被聚合、整合、优化，形成综合方案 | 协商的自然终止态——Center 输出 `plan` 或 `contract` 类型时触发 |
| `gap.identify` | 方案中发现无法被现有响应满足的部分 | 白皮书定义保留 |
| `sub_demand.create` | 缺口转化为独立的子需求，触发递归 | 明确为独立事件 |

#### 执行阶段事件（2026-02-07，Design Log #002）

> 当 Center 输出 `contract` 类型时，方案进入执行阶段，产生以下事件：

| 事件 | 语义 | WOWOK 对应 |
|------|------|-----------|
| `contract.create` | Center 方案转化为可执行合约 | Machine 创建（bPublished=false） |
| `contract.publish` | Machine 发布（不可修改） | Machine.publish (bPublished=true) |
| `contract.accept` | 参与方购买 Service / 接受合约 | Service 购买 → Order 创建 → OnNewOrder |
| `task.progress` | workflow 推进到新节点 | Progress.next (Forward 操作) → OnNewProgress |
| `task.deliver` | 参与方提交交付物 | Forward.deliverable + Repository（可选） |
| `contract.complete` | Progress 执行到终点 | Progress 状态 = completed |
| `contract.settle` | 经济结算（如有） | Treasury 转账/结算 |

#### 回声事件

| 事件 | 语义 | 触发 |
|------|------|------|
| `echo.pulse` | 单个回声脉冲到达 | 每个执行阶段事件自动生成 |
| `echo.digest` | 回声汇聚为 Profile 更新 | 合约完成时批量处理，回流到 ProfileDataSource |

详细设计见 Section 11（执行与回声阶段）。

#### 关于 `plan.distribute` 和 `response.confirm`

白皮书定义了"方案分发"和"响应确认"。在架构讨论中（2026-02-07），我们确立了：**确认不是独立步骤，而是协商的三种穷举终止态之一（继续协商 / 退出 / 无异议即确认）。** 方案输出后的通知、确认、展示属于应用层行为，用户可自定义。

这不是与白皮书矛盾——白皮书的语义（"方案需要被响应者表态"）被保留了，只是不作为协议层的独立事件，而是作为协商轮次内部的自然状态转换处理。

## 4. 状态管理与部署策略

> 原 Section 4（状态管理）+ 原 Section 6.1/6.2/6.4 合并。筛选阶段的状态检测、部署模式、收集完成判断本质上都是"系统如何运行"的高层决策，与状态管理同属一类。

### 4.1 设计原则

**能少一个环节就少一个环节**：减少复杂度，减少出错的地方。

### 4.2 协作组状态

只需要两个状态：

| 状态 | 描述 |
|------|------|
| `negotiating` | 协商进行中 |
| `completed` | 协商完成（有结果，无论完美还是妥协） |

不需要 `forming`、`confirming`、`failed`、`cancelled`：
- 方案确认是协商的一部分，不需要单独状态
- 协商总会有结果，不存在"失败"或"取消"

### 4.3 Agent状态

| 状态 | 描述 |
|------|------|
| `active` | 活跃，参与协商 |
| `replied` | 本轮已回复 |
| `exited` | 已退出 |

### 4.4 状态检测机制

**核心假设**：Agent是AI，不是人。
- AI不会"忘记回复"
- AI不会"拖延"
- 如果AI决定不参与，它会明确说"退出"
- 如果AI的服务挂了，那是基础设施问题，不是协议问题

**因此**：每个Agent要么回复，要么退出，不存在"沉默"。协议层不需要超时机制。但基础设施层需要超时作为容错手段（Agent 服务不可达时，等待屏障标记其为"退出"并继续）。

**实现方式**：

```
中心Agent发送本轮信息给所有active的Agent
    ↓
维护一个"待响应列表" = 所有active的Agent
    ↓
每收到一个回复（或退出通知）：
    - 从"待响应列表"中移除该Agent
    - 如果是退出，更新Agent状态为exited
    - 如果是回复，更新Agent状态为replied
    ↓
当"待响应列表"为空时：
    - 所有Agent都有了明确状态
    - 进入聚合阶段
```

**基础设施层的职责**：
- 监控Agent服务的健康状态
- 如果检测到Agent服务不可用，通知中心Agent
- 中心Agent将该Agent视为"退出"

### 4.5 状态存储

**方案**：持久化存储（PostgreSQL）

**原因**：
1. 协商可能持续较长时间
2. 需要支持恢复（中心Agent服务重启后能继续）
3. 需要审计和追溯
4. Offer沉淀本身就需要持久化

**存储内容**：

| 数据 | 描述 |
|------|------|
| 协商元数据 | 协商ID、需求ID、状态、创建时间 |
| 参与者列表 | 哪些Agent参与、各自状态 |
| 轮次记录 | 每一轮的信息和回复 |
| 当前轮次状态 | 当前是第几轮、待响应列表 |

### 4.6 筛选阶段的状态检测

> 原 Section 6.1。

Agent一定会返回结果（是或否），因为：
- Agent以语言为存在本身
- 无论用大模型还是前置筛选逻辑，都会返回一个结果
- 前置筛选是**并发的**，不会出现"永远不回复"的情况

### 4.7 两种部署模式

> 原 Section 6.2。

| 模式 | 描述 | 状态检测 |
|------|------|---------|
| **统一设备** | 所有Agent运行在我们的设备上 | 时间和状态可预估 |
| **分布式设备** | Agent运行在用户自己的设备上 | 网络速度不一样，需要其他逻辑 |

### 4.8 收集完成的判断（等待屏障）

> 原 Section 6.4。
> 2026-02-07 决策：采用**等待屏障（Barrier）**机制（见 Section 10.2 步骤 ⑤）。

程序层维护"待响应列表"（所有被 HDC 共振激活的 Agent）。每收到一个 Offer 或退出通知，从列表中移除。列表为空时 → 所有 Offer 已收集，进入 Center 综合。协议层没有超时概念——Agent 要么返回 Offer，要么主动退出。基础设施层作为容错手段检测进程故障（Agent 服务不可达时标记为"退出"并继续）。

这是广播阶段的收集判断，与协商阶段的轮次管理（Section 4.4）逻辑一致。

## 5. Peer-to-Peer 发现性对话

> 2026-02-07 重写，与 Section 10.8（SubNegotiationSkill）对齐。
> 核心认知：P2P 不是"辩论"（双方拿相同信息争论，研究证实效果为负），而是**"发现性对话"**（双方各自有不同的深层信息，对话激发新发现）。

### 5.1 触发条件

由中心Agent判断是否需要触发 P2P（作为 `trigger_p2p` 决策类型输出）：

| 触发条件 | 描述 |
|---------|------|
| **互补检测** | 两个 Agent 的 Offer 高度互补，可能有更深的协作价值 |
| **冲突检测** | 两个 Agent 的 Offer 有冲突，需要找到协调路径 |
| **隐藏价值** | Agent 的 Profile 中有 Offer 未提及的相关能力 |

### 5.2 为什么是"发现"而不是"辩论"

研究背景（见 Section 10.2 研究支撑）：
- Multi-Agent Debate 平均效果 -3.5%（Google DeepMind, 2025）
- 但那些研究的前提是：参与者拿到**相同信息**进行争论

通爻网络的 P2P 本质不同：
- 端侧 Agent 持有**独特的 Profile / SecondMe 上下文**
- 初始 Offer 不一定覆盖 Agent 所有相关能力
- 对话可以激发"我没想到的、但实际上我有的"价值
- 这是信息不对称下的**发现**，不是信息对称下的辩论

### 5.3 V1 方案：第三方综合（一次 LLM 调用）

```
Center 触发 P2P（指定两个 Agent + 原因）
    ↓
收集输入：
    - 触发原因（冲突/互补/隐藏价值）
    - Agent A 的 Offer + Profile
    - Agent B 的 Offer + Profile
    ↓
一次 LLM 调用（SubNegotiationSkill）
    关注 Profile 中 Offer 未涉及的部分
    寻找意想不到的互补和组合
    ↓
输出：发现报告
    - 新发现的关联
    - 协调方案（如有冲突）
    - 各方可能的额外贡献
    ↓
结果回流到 Center，纳入下一次综合
```

### 5.4 数据结构

```python
class SubNegotiation:
    """发现性对话"""
    sub_session_id: str
    parent_session_id: str
    participants: List[str]       # 两个 Agent
    trigger_reason: str           # 触发原因
    status: str                   # processing | completed
    result: Optional[DiscoveryReport]

class DiscoveryReport:
    """发现报告"""
    new_associations: List[str]   # 新发现的关联
    coordination: Optional[str]   # 如有冲突，协调方案
    additional_contributions: Dict[str, str]  # 各方的额外贡献
    summary: str                  # 发现摘要
```

### 5.5 结果整合

发现报告回流到 Center Agent 的下一次调用，作为额外 context。Center 决定如何将新发现整合进方案。

### 5.6 未来：端侧 Agent 直接对话

V1 用第三方 LLM 综合，简单可控。未来可扩展为端侧 Agent 直接对话：
- A 和 B 各自基于自己的 SecondMe 上下文回应
- 能激发出第三方无法发现的深层关联
- 需控制轮次（最多 1-2 轮）避免错误传播

详见 Section 10.8 SubNegotiationSkill 的接口定义。V1 Prompt 见 `docs/prompts/sub_negotiation_v1.md`。

## 6. HDC 签名与共振检测

> 原 Section 6.3（签名共振机制），独立为新 Section。这是通爻网络最核心的技术机制——超维计算（HDC）用于签名编码和共振检测。原 Section 6.1/6.2/6.4 已移入 Section 4（状态管理与部署策略），原 Section 6.5 已移入 Section 7（Agent 接入与 Profile 管理）。

### 6.1 签名共振机制

> 讨论日期：2026-02-06
> 核心认知：**广播和筛选是同一个逻辑，只是方向相反。** 同一个数学操作（超向量相似度计算）既用于传播时的转发决策，也用于端侧的共振检测。

#### 6.1.1 设计目标

- **复杂度**：O(N+M)，不是 O(N×M)
- **端侧检测**：每个Agent本地判断，不需要中心化匹配
- **足够抽象**：不是标签匹配或任务类型分类，而是语义共振。任何形式的文本（需求、情绪、诗歌、随想）都能被处理
- **发现未知关联**：不仅匹配已知兴趣，还能发现Agent自己都不知道的关联
- **能量效率**：99%在低能耗层过滤，只有1%进入大模型处理

#### 6.1.2 核心机制：超维计算（Hyperdimensional Computing / HDC）

**基本原理**：

所有信息（Agent画像、消息签名）都表示为 D=10,000 维的二进制超向量。在这个空间中：
- 随机生成的向量几乎必然近似正交（互不干扰）
- 空间容量为 2^10,000（实际上无限大）
- 相似度通过 Hamming 距离计算，O(D) 复杂度，< 100 纳秒

**三个核心操作**：

| 操作 | 数学实现 | 作用 | 类比 |
|------|---------|------|------|
| 绑定 (Bind) | XOR（异或） | 编码关系："A与B有关联" | 两种气味锁在一起 |
| 捆束 (Bundle) | 逐位加法 + 阈值化 | 创建复合画像："我关心A、B、C" | 多种气味混合 |
| 相似度 | Hamming距离 / 余弦 | 判断共振强度 | 闻到相似的味道 |

**关键特性**：捆束操作产生**干涉模式**。将"分布式系统"+"共识"+"容错"捆束后，结果向量会与"区块链治理"产生非零相似度——即使从未声明这两者有关。这是发现未知关联的数学基础。

参考论文：
- Kanerva, "Hyperdimensional Computing" (Cognitive Computation, 2009)
- Kleyko et al., "A Survey on Hyperdimensional Computing (VSA)" (ACM Computing Surveys, 2023)
- Cohen et al., "Discovering discovery patterns with predication-based Semantic Indexing" (2013)

#### 6.1.3 三层共振过滤架构（完整愿景）

```
信号进入
    │
    ▼
┌─────────────────────────────────────────────┐
│  第一层：Bloom Filter 门控                    │
│  成本：~100ns    过滤：90% 的信号              │
│  机制：已知关键词的位向量匹配                    │
│  发现未知关联：不能                             │
└─────────────────────┬───────────────────────┘
                      │ 10% 通过
                      ▼
┌─────────────────────────────────────────────┐
│  第二层：HDC 共振检测                          │
│  成本：~1μs      过滤：剩余的 90%              │
│  机制：10,000维超向量 Hamming 相似度            │
│  发现未知关联：可以（通过几何干涉）              │
└─────────────────────┬───────────────────────┘
                      │ 1% 通过
                      ▼
┌─────────────────────────────────────────────┐
│  第三层：深度评估（大模型/主动推理）             │
│  成本：~10ms     处理：1% 的信号                │
│  机制：预测误差 + 语义理解                      │
│  发现未知关联：可以（通过预测误差）              │
└─────────────────────┬───────────────────────┘
                      │
                      ▼
                 Agent被激活 → 生成 Offer
```

**V1 决策：只实现第二层（HDC），第一层和第三层后续版本添加。**

理由：1000个Agent规模下，HDC的0.1ms/消息性能已经足够，不需要Bloom Filter加速；第三层用现有LLM直接替代。

#### 6.1.4 编码流程

**将任意文本转化为超向量的三步流程：**

```
步骤一：文本 → 语义嵌入（可插拔编码器）
─────────────────────────────────────────────
任意文本（需求、情绪、诗歌、代码，任何内容）
    ↓
编码器（默认：sentence-transformers，可替换）
    ↓
[浮点向量，如768维]

步骤二：浮点向量 → 二进制超向量（SimHash投影）
─────────────────────────────────────────────
[768维浮点数]
    ↓
SimHash（10,000个随机超平面投影，全网共享）
    ↓
[10,000维二进制] = 超向量

关键性质：语义上接近的文本，转换后Hamming距离也小

步骤三：超向量绑定到Agent或消息
─────────────────────────────────────────────
Agent画像 = bundle(H_技能1, H_技能2, H_经历1, ...)
消息签名 = encode(消息文本)
```

**编码器可插拔性**：

HDC层（第二步和第三步）不关心编码器是什么。只要输入是一个浮点向量，就能转换为超向量。因此：
- 前期用 sentence-transformers（免费，768维）
- 中期可换 OpenAI embedding（更强，1536维）
- 后期可训练自己的领域模型
- 甚至不同Agent可以使用不同编码器

SimHash投影矩阵在编码器切换时需要重新生成，但超向量空间的性质不变。

#### 6.1.5 Agent画像的生成与演化

> **2026-02-07 架构简化**：Design Log #003 确立了"投影即函数"原则。Agent 不是有状态对象，而是投影函数的结果。本节描述 HDC 编码的技术流程，画像的演化机制见 Section 7.1.6（ProfileDataSource 与投影机制）。

**投影式画像生成**：

```
ProfileDataSource.get_profile(user_id) → Profile Data
    ↓
每项信息编码为超向量（sentence-transformers + SimHash）
    ↓
bundle(所有超向量) = project(profile_data, lens)
    ↓
Agent 画像 = 投影函数的结果（无状态，可重复计算）
```

**画像演化**：

画像不是通过"融合"或"经验生长"更新的，而是通过数据源更新 + 重新投影实现的：

```
协作发生 → 协作数据回流到 ProfileDataSource
    ↓
数据源自己处理更新（SecondMe 更新档案、Claude 更新记忆...）
    ↓
下次调用 project(profile_data, lens) → 自然反映新经验
```

**关键**：通爻不维护 Agent 状态，不需要 Random Indexing 或 blend 融合。"画像演化"是数据源演化 + 重新投影的自然结果。详见 Section 7.1.6。

参考：Sahlgren, "An Introduction to Random Indexing" (2005) — V2+ 可能在数据源内部使用，但不在投影层。

#### 6.1.6 共振检测流程

**核心认知：广播和筛选是同一个数学操作。**

**需求广播 → 供给方共振（谁来响应我？）**：

```
需求文本（经 formulation 丰富化）→ 编码为超向量 H_demand → 广播到网络
每个 Agent 本地计算：similarity(H_agent, H_demand) > θ_supply ?
共振 → Agent被激活 → 用大模型深度理解需求 → 生成Offer
```

> **2026-02-07 决策**：原设计有"需求方共振"作为独立的二次筛选步骤，已取消。原因：硬筛选会阻止"意外发现"（见 Section 1.2）。需求方偏好通过 formulation 编织进 HDC 签名（前置）和 Center context（后置）表达，不通过独立的 Offer 过滤步骤。

#### 6.1.7 传播机制

**V1：简单广播**

1000个Agent规模下，中心直接广播到所有Agent，每个Agent本地做共振检测。性能足够（一条消息的全网共振检测 < 0.1ms）。

**未来：语义Gossip**

规模增长到万级以上时，切换为Gossip协议：
- 每个节点只向3个随机邻居传播
- O(log N)轮次覆盖全网（1000 Agent ≈ 7轮）
- 每次转发前用Bloom Filter检查邻居画像，不感兴趣的不转发
- 信息自动沿"相关性路径"传播

这个切换不影响协议层（共振检测逻辑不变），只是基础设施层的传播方式改变。

参考论文：
- GEACL: Gossip-Enhanced Agentic Coordination Layer (arXiv:2512.03285)
- Revisiting Gossip Protocols for Multi-Agent Systems (arXiv:2508.01531)

#### 6.1.8 性能预估（V1：1000 Agent，100 消息/秒）

| 指标 | 值 |
|------|-----|
| 每次共振检测 | < 100 纳秒 |
| 每条消息 × 1000 Agent | ~0.1 毫秒 |
| 100 消息/秒 | ~10 毫秒/秒 |
| CPU 占用 | ~1% |
| 每个Agent画像大小 | 1.25 KB |
| 1000 Agent画像总内存 | ~1.2 MB |

#### 6.1.9 技术选型总结

经过对7种技术方案（Bloom Filter、LSH、HDC、MoE、主动推理、语义Gossip、Bloom P2P路由）的对比分析：

| 需求 | 选择 | 理由 |
|------|------|------|
| 核心表示 | HDC（超维计算） | 语义匹配 + 发现未知关联 + 端侧友好 + O(D)复杂度 |
| 初始编码 | sentence-transformers + SimHash | 零训练成本，第一天即可工作，可插拔 |
| 画像演化 | Random Indexing | 从经验中自动生长，不需要重新训练 |
| V1传播 | 简单广播 | 1000 Agent规模下足够 |
| 未来传播 | 语义Gossip | 万级以上规模时切换，O(log N)覆盖 |
| 第一层门控 | Bloom Filter（V2+） | 10万+Agent时添加，进一步降低能耗 |
| 深度评估 | LLM（V1）/ 主动推理（V3+） | V1用现有LLM，后续探索主动推理框架 |

#### 6.1.10 共振阈值策略（θ 与 k* 机制）

> 讨论日期：2026-02-07
> 核心洞察：**θ 不应该是预设常数，而是从期望响应数 k\* 中计算出来的。** 本质与实现分离：k\* = 本质（业务参数），θ = 实现（技术参数）。

**问题背景**：

共振阈值 θ 是系统的"神经敏感度"：
- **θ 太高** → 遗漏好的 Agent（假阴性，机会成本）
- **θ 太低** → 大量无关 Agent 通过（假阳性，计算成本）

直接设定 θ 存在问题：
- θ 是技术参数（0.65？0.7？），场景组织者无法理解
- 同样的 θ，在 N=100 和 N=10000 时效果完全不同
- 不同场景需求差异大（黑客松 vs 创业社区），难以统一

**核心设计：k\*（期望响应数）机制**

**基本原理**：

与其直接设定 θ（相关度分数），不如设定 **k\***（期望响应数）：
- 场景组织者设定：我希望大约有 k\* 个 Agent 响应
- 系统自动计算：找到一个 θ，使得共振通过数 ≈ k\*
- θ 随 Agent 数量（N）、Profile 分布、需求签名自动调整

**为什么 k\* 是更好的抽象**：

1. **k\* 是业务语言，θ 是技术参数**
   - 场景组织者能理解"我希望 10 个人响应"
   - 场景组织者不理解"相关度阈值应该设为 0.65"

2. **k\* 直接关联成本**
   - 总成本 = 筛选成本（O(N) × HDC_cost）+ 处理成本（O(k) × LLM_cost）
   - 只要 k > 10，处理成本就主导（LLM 比 HDC 贵 10000 倍）
   - 预算 $10，LLM $0.01/次 → k\* = 1000

3. **k\* 与 N 解耦**
   - N = 100 和 N = 10000 时，k\* = 10 的含义一样（都是 10 个响应）
   - 但对应的 θ 完全不同（通过率 10% vs 0.1%）

4. **k\* 可以从场景语义推导**
   - 黑客松组队（3-5 人小队）→ k\* = 15-20（多样性 + 可选择）
   - 创业找联创（1-2 人）→ k\* = 5-10（质量优先）
   - 社交场景（认识新朋友）→ k\* = 30-50（探索意外）
   - 专业服务（标准化需求）→ k\* = 3-5（快速响应）

**θ 的计算方法**（实现层面，标识为子课题）：

```
给定：
  - 需求签名 H_demand
  - 所有 Agent 的 Profile {H_agent1, H_agent2, ..., H_agentN}
  - 期望响应数 k*

计算：
  1. 计算所有 Agent 的共振分数：
     scores = [H_agent_i @ H_demand for i in 1..N]

  2. 排序（降序）

  3. 取第 k* 个分数作为 θ：
     θ = scores[k*]

  4. 共振通过条件：
     score > θ → Agent 产生响应
```

**关键特性**：
- θ 不是预设的，而是从当前 Agent 分布和需求签名中**计算**出来的
- 相对排名机制：总是选出"最相关的 k\* 个"，而不是"分数超过固定阈值的所有"
- 自动适配 N：Agent 数量变化时，k\* 不变，θ 自动调整

**场景配置示例**：

```json
{
  "scene_id": "hackathon_2026",
  "name": "黑客松快速组队",
  "config": {
    "expected_responders": 20,
    "description": "鼓励多样性，快速组队"
  }
}
```

```json
{
  "scene_id": "startup_cofounder",
  "name": "创业找联创",
  "config": {
    "expected_responders": 8,
    "description": "质量优先，精准匹配"
  }
}
```

场景组织者只需设定 k\*，系统自动计算 θ。

**自适应策略（V2）**：

现在有了回声信号（Task #1 完成），可以根据执行反馈自动调整 k\*：

```
统计数据（每个场景独立追踪）：
  共振通过的 Agent 集合 R（|R| ≈ k*）
  产生 Offer 的 Agent 集合 O ⊆ R
  进入方案的 Agent 集合 P ⊆ O
  执行成功的 Agent 集合 E ⊆ P（回声信号）

质量指标：
  Offer 率 = |O| / |R|（通过后多少真的响应）
  采纳率 = |P| / |O|（Offer 多少进方案）
  成功率 = |E| / |P|（方案多少真执行）

调整策略：
  如果 Offer 率 < 50%  → k* 太大，减少（× 0.8）
  如果成功率 < 30%     → 质量问题，k* 减少（× 0.7）
  如果成功率 > 80% 且 Offer 率 > 80% → 质量很高，可增加覆盖（× 1.2）
```

**冷启动问题的解决**：

新 Agent 没有执行历史，但有初始 Profile：
- **SecondMe 数据**：技能、专长、兴趣 → 编码为 HDC 向量（见 6.1.5）
- **显式标签**：用户注册时的自我描述
- **场景选择**：用户加入的场景 → 隐式兴趣

新 Agent 的 Profile 不是空的，而是从注册信息初始化。k\* 机制是相对排名，如果新 Agent 的初始 Profile 与需求相关，自然会通过。**不需要"新手保护"特殊处理。**

**V1/V2/V3 演化路径**：

| 版本 | k\* 策略 | θ 计算 | 实现复杂度 |
|-----|---------|--------|----------|
| V1 | 场景配置固定 k\* | 排序取第 k\* 个 | 简单，立即可用 |
| V2 | 场景自适应 k\*（基于回声反馈） | 同 V1 | 中等，自动优化 |
| V3 | Agent 级异构成本（带权重的 k\*） | 背包问题优化 | 复杂，最优解 |

**符合设计原则**：
- **0.2 本质与实现分离**：k\* = 本质，θ = 实现
- **0.7 复杂性从简单规则生长**：一个规则（k\*），适配不同场景、不同 N
- **0.8 投影是基本操作**：k\* 定义透镜的焦距，θ 是焦距对应的光圈大小

**待深入研究的子课题**：
- θ 计算的精确算法优化（排序 O(N log N) vs 快速选择 O(N)）
- 自适应策略的参数调优（调整速率、平滑窗口、最小样本量）
- 成本模型的细化（不同 LLM 的成本差异、HDC 计算的实际开销）
- Agent 级异构性处理（V3，不同 Agent 的"响应成本"不同）

## 7. Agent 接入与 Profile 管理

> 原 Section 6.5（Agent 接入机制），独立为新 Section。包含注册、画像生成、Service Agent、ProfileDataSource 等。

### 7.1 Agent 接入机制

> 讨论日期：2026-02-06
> 核心认知：**Agent 就是你的 Profile。** 用户不需要知道"Agent"是什么，不需要会编程。填写信息 → 系统生成 HDC 画像 → Agent 在网络中活跃。接入的门槛从"会编程"降到"会打字"。

#### 7.1.1 V1 模式选择：平台模式（协议 DNA 内置）

**决策：V1 用平台模式，但协议的 DNA 从第一天就埋进去。**

理由：要先控制住变量，才能证明机制有效。

| | 平台模式（V1） | 协议模式（未来） |
|--|---------------|----------------|
| Agent 运行在哪 | 我们的基础设施 | 用户自己的设备 |
| 身份由谁管 | 我们分配 | Agent 自己持有（如 DID） |
| 通信方式 | 连我们的 WebSocket | 任意，只要符合协议 |
| 画像由谁算 | 我们计算并存储 | Agent 端侧自己算 |
| 信任模型 | 场景准入 | 密码学证明 |

**兼容性设计**：数据结构从第一天就兼容协议模式。

```
AgentIdentity {
    id: string              // V1: UUID → 未来: DID
    display_name: string
    source_type: string     // "secondme" | "claude" | "template" | "custom"
    agent_type: string      // V1: 始终为 "edge"。未来: "edge" | "service"
    parent_id: Optional[string]  // V1: 始终为 null。未来: Service Agent 指向 Edge Agent
    profile: HDCVector      // 10,000维超向量画像
    scenario_id: Optional[string]  // 所属场景（Edge Agent 可为 null，面具绑定场景）
    created_at: timestamp
    metadata: {}            // 可扩展字段
}
```

切换到协议模式时，网络内的其他组件（共振检测、协商、方案生成）不需要改动。

#### 7.1.2 身份系统

V1 由平台签发，数据结构兼容未来 DID：
- 注册时签发 `agent_id`（UUID）+ `auth_token`
- 身份绑定到 HDC 画像
- 未来 `agent_id` 可替换为 DID，上层逻辑无感知

#### 7.1.3 通信机制

V1 采用 WebSocket（集中式）：

```
                    ┌──────────────┐
                    │   通爻服务器   │
                    └──────┬───────┘
              ┌────────────┼────────────┐
         WebSocket    WebSocket    WebSocket
         ┌────┴───┐  ┌────┴───┐  ┌────┴───┐
         │Agent A  │  │Agent B  │  │Agent C  │
         └────────┘  └────────┘  └────────┘
```

**关键**：消息格式才是协议，传输方式只是基础设施。

```json
{
    "type": "demand.broadcast",
    "source_id": "agent_xxx",
    "signature": "<HDC超向量>",
    "payload": {},
    "timestamp": 1738828800
}
```

V1 是消息经过服务器中转。未来可改成 P2P 直连，消息格式不变。

#### 7.1.4 信任模型：场景准入

**核心认知：信任不只是"这个人是不是坏人"，更是"这个 Agent 有没有足够丰富的上下文"。**

上下文稀薄的 Agent 对网络的伤害：
1. **噪音**：超向量缺乏纹理 → 对太多信号假阳性共振 → 低质量 Offer 涌入
2. **稀释**：好的 Offer 被平庸 Offer 淹没
3. **自身体验差**：贡献不了价值 → 用户觉得"通爻没用"
4. **口碑损害**：早期用户体验决定网络能否增长

**方案：场景准入（不筛用户，筛场景）**

不限制"谁能来"，限制"在什么场景下来"。每个场景自带上下文丰富度保障。

场景 = 有明确主题、有组织者、参与者自然有丰富上下文的环境。

示例：
- AI创业者社区（成员有丰富的技能/经验/偏好数据）
- 黑客松活动（参赛者有明确的能力和项目方向）
- 公司内部资源协调（员工的技能/项目/职责有记录）

**优势**：
- 上下文丰富度是场景自带的，不需要"筛选用户"
- 组织者承担质量保障的角色
- 小而密比大而稀好——30个上下文丰富的 Agent 比 3000 个空壳 Agent 有用得多
- 每个成功的场景就是一个案例，用来吸引下一个场景

**辅助手段：HDC 信息熵检测**

```
Agent 注册时 → 生成 HDC 超向量 → 计算 specificity score

specificity = 1 - cosine_similarity(H_agent, H_average)

score < 0.3 → 提示"画像比较泛，建议补充更多信息"（引导，不阻止）
score > 0.6 → "画像丰富度很好"
```

#### 7.1.5 多源接入：Adapter 架构

不同来源的 Agent 通过 Adapter 接入，核心注册逻辑不变。

```
┌─────────────────────────────────────────────┐
│              统一注册接口                      │
│    输入：文本片段[] + 元数据                   │
│    处理：HDC 编码 → 超向量画像                 │
│    输出：agent_id + auth_token + profile     │
└──────────────────┬──────────────────────────┘
                   │
      ┌────────┬───┴───┬──────────┬──────────┐
      ▼        ▼       ▼          ▼          ▼
  SecondMe   Claude  Template   GPT/其他   Custom
  Adapter    Adapter  Adapter   Adapter    Adapter
      │        │       │          │          │
  OAuth获取  解析系统  用户填写    API解析    开发者
  个人数据   提示词    表单        能力描述   自建
```

所有 Adapter 实现同一个接口：
- `extract_profile_text()` → 从数据源提取文本片段
- `get_capabilities()` → 提取能力描述
- `validate_source()` → 验证数据源有效性

| 来源 | 上下文类型 | 丰富度 | Adapter 做什么 |
|------|-----------|--------|---------------|
| SecondMe | 个人经历、技能、偏好、价值观 | 高 | OAuth 获取用户数据 |
| Claude/GPT Bot | 系统提示词、能力配置 | 中 | 解析 system prompt |
| Template（表单） | 用户自己填写 | 视场景 | 接收表单数据 |
| Custom（API） | 开发者定义 | 视实现 | 接收结构化 API 数据 |

#### 7.1.6 ProfileDataSource 与投影机制（2026-02-07 架构简化）

> **核心突破**（Design Log #003）：Agent 是投影函数的结果，不是有状态对象。ProfileDataSource 是可插拔接口，通爻只负责投影，不维护状态。

##### 核心洞察：投影即函数

**错误的理解**（过度复杂）：
```
Profile Data → 初始化 → Edge Agent（有状态对象）
                      → 不断更新 → 需要防漂移机制
```

**正确的理解**（极度简单）：
```
ProfileDataSource（数据源，可插拔）
       ↓
投影函数（无状态）
       ↓
Edge Agent Vector = project(profile_data, lens="full_dimension")
Service Agent Vector = project(profile_data, lens="focus_on_X")
```

**关键原则**：
- **Agent 是投影，不是对象**：每次需要时重新计算，不存储状态
- **数据源可插拔**：SecondMe / Claude / GPT / Template / Custom 都是 Adapter
- **协作数据回流到数据源**：通爻记录协作数据，回流到数据源，数据源自己更新 Profile
- **通爻只投影**：从数据源读取 → 投影 → Agent Vector，不维护 Profile 状态

##### ProfileDataSource 接口（抽象）

所有 Adapter 实现统一的 ProfileDataSource 接口：

```python
class ProfileDataSource(ABC):
    """
    Profile 数据源的抽象接口

    SecondMe / Claude / GPT / Template / Custom 都实现这个接口
    """

    @abstractmethod
    def get_profile(self, user_id: str) -> ProfileData:
        """
        获取用户的 Profile 数据

        返回：ProfileData（包含能力、经验、偏好等）
        """
        pass

    @abstractmethod
    def update_profile(self, user_id: str, experience_data: dict) -> bool:
        """
        更新用户的 Profile（协作数据回流）

        参数：
        - user_id: 用户 ID
        - experience_data: 协作经验数据（来自 WOWOK 链上）

        返回：是否更新成功
        """
        pass

    @abstractmethod
    def validate_source(self) -> bool:
        """验证数据源是否可用"""
        pass
```

**关键设计**：
- `get_profile()` 是读取接口（通爻从数据源读取）
- `update_profile()` 是写入接口（协作数据回流到数据源）
- 数据源自己决定如何处理更新（通爻不管）

##### 投影函数：从 Profile Data 到 Agent Vector

```python
def project(profile_data: ProfileData, lens: str) -> HDCVector:
    """
    投影函数：从 Profile Data 投影出 Agent 的 HDC 向量

    参数：
    - profile_data: 来自 ProfileDataSource 的数据
    - lens: 透镜类型
      - "full_dimension": 全维度投影 → Edge Agent
      - "focus_on_X": 聚焦 X 领域 → Service Agent

    返回：HDC 超向量（10,000 维）
    """
    if lens == "full_dimension":
        # Edge Agent: 全维度投影
        return encode_full_dimension(profile_data)

    elif lens.startswith("focus_on_"):
        # Service Agent: 聚焦投影
        domain = lens.replace("focus_on_", "")
        return encode_focused(profile_data, domain)

    else:
        raise ValueError(f"Unknown lens: {lens}")
```

**关键特性**：
- **无状态**：投影是纯函数，不依赖外部状态
- **可缓存**（实现层面）：如果 Profile Data 没变，可以缓存结果
- **可替换**（本质与实现分离）：编码方式可以从 HDC 换成其他（如 BERT embeddings）

##### 透镜（Lens）的本质定义

> 2026-02-08 补充。Task #3 收尾：架构层定义完成，实现细节标记为子课题。

**透镜是什么**：透镜是一个**维度选择器**——它决定 Profile Data 的哪些方面参与 HDC bundle。

```
Profile Data = {技能, 经验, 偏好, 价值观, 项目经历, 社交关系, ...}

全维度透镜（Edge Agent）：
    bundle(encode(技能), encode(经验), encode(偏好), encode(价值观), ...)
    → 信噪比低，但能捕捉跨域干涉

聚焦透镜（Service Agent）：
    bundle(encode(技能.frontend), encode(经验.web_dev), encode(项目.react_apps))
    → 信噪比高，快速精准响应特定领域
```

**透镜的本质是同一个操作**——投影。不同透镜只是改变了输入维度的选取范围，投影操作本身不变。这与设计原则 0.8（投影是基本操作）完全一致。

**透镜的三种来源**（V1 只实现前两种）：

| 来源 | 描述 | V1 |
|------|------|-----|
| 默认透镜 | `full_dimension`，注册时自动生成 Edge Agent | ✅ |
| 场景透镜 | 场景 Template 定义关注维度，用户手动创建 Service Agent | ✅ |
| 经验透镜 | HDC 空间中检测经验聚类，提示用户沉淀 Service Agent | V2+ |

**架构层约束**（稳定）：
- 透镜不改变 Profile Data，只改变投影的选取范围
- 同一份 Profile Data 可以通过不同透镜产生多个 Agent Vector
- 透镜本身可序列化（可存储、可传播、可复用）

**实现层子课题**（可演化，不在架构层展开）：
1. 透镜参数的具体数据格式（字段选择器？权重向量？语义描述？）
2. `encode_focused()` 的实现策略（子集 bundle？加权 bundle？语义过滤？）
3. 场景 Template → 透镜的转换逻辑
4. 透镜的管理 UX（创建、编辑、删除）
5. V2 经验聚类的检测算法

##### 协作数据回流机制

```
Step 1: 协作发生（WOWOK 链上）
────────────────────────
  需求 → 协商 → 方案 → Machine → Progress
  Progress Forward 操作 → 链上事件（OnNewOrder, OnNewProgress, ...）
        ↓
Step 2: 通爻记录
────────────────────────
  监听链上事件 → 提取协作数据 → 本地记录
        ↓
Step 3: 回流到数据源
────────────────────────
  定期同步（或实时）
  调用 ProfileDataSource.update_profile(user_id, experience_data)
        ↓
Step 4: 数据源处理更新
────────────────────────
  SecondMe: 更新个人档案
  Claude: 更新系统上下文
  GPT: 更新记忆
  Template: 累积经验记录
        ↓
Step 5: 下次投影时自然生效
────────────────────────
  get_profile() 返回更新后的数据
  project() 重新计算 Agent Vector
  → Profile 自然演化，无需"维护状态"
```

**关键优势**：
- **极度简单**：通爻不需要"Profile 更新算法"
- **真正的完备性**：数据在源头，通爻保持连通（窗户 vs 照片）
- **可插拔**：不同数据源可以有不同的更新策略
- **反脆弱**：即使通爻的投影机制失败，数据已回流到源头，仍有价值

##### 三句话解释系统

1. **ProfileDataSource 是数据源**（SecondMe / Claude / GPT / ...）
2. **协作数据回流到数据源**，数据源自己更新 Profile
3. **通爻从数据源投影**：Edge Agent = 全维度，Service Agent = 聚焦维度

##### V1 实现策略

**V1 的数据流**：
```
SecondMe OAuth → 获取 Profile Data → 投影成 Edge Agent Vector → 存入通爻数据库
                                    ↓
                              用于共振检测、Offer 生成
                                    ↓
                        协作数据（WOWOK 链上）→ 记录
                                    ↓
                    （V1 暂不回流，V1b 引入回流机制）
```

**为什么 V1 暂不回流**：
- V1 目标：证明"投影机制 + 共振检测 + 协商"可以工作
- 回流机制需要与 SecondMe 协调 API（需要时间）
- V1 可以先用"静态 Profile"，数据结构预留回流接口

**V1b/V2 引入回流**：
- 与 SecondMe 对接：定期同步协作数据
- 与其他 Adapter（Claude / GPT）对接：根据各自 API 设计回流方式
- Template Adapter：通爻自己维护经验记录

##### 消除的复杂性

基于"投影即函数"的架构，以下复杂性被消除：

| 之前的设计 | 问题 | 新设计 | 优势 |
|----------|------|--------|------|
| Profile 更新算法 | 需要设计复杂的加权融入机制 | 数据源自己处理 | 简单，可插拔 |
| 防漂移机制 | 需要锚定、维度平衡、周期性校准 | 投影函数无状态，不会漂移 | 极度简单 |
| 冷启动策略 | 新 Agent 如何快速建立画像 | 数据源已有初始数据 | 不需要特殊处理 |
| 状态维护 | Edge Agent 和 Service Agent 的状态管理 | 每次重新投影，不存储状态 | 无状态，易扩展 |

##### 相关设计文档

- Design Log #003: `docs/DESIGN_LOG_003_PROJECTION_AS_FUNCTION.md`
- Task #3（简化版）：Service Agent 透镜机制

#### 7.1.7 Agent 模板（Template Adapter）

**定位：万能兜底 Adapter。** 任何来源、任何场景，最终都能退化为"给我一些文本 → 我帮你变成 Agent"。

**Template 数据结构**：

```
Template {
    template_id: string
    name: "黑客松2026参赛者"
    scenario_id: string
    created_by: string              // 主办方/运营方

    fields: [                       // 主办方可自定义
        {
            key: "skills"
            label: "你的技术栈"
            type: "text"
            hint: "比如：Python, React, 机器学习..."
            required: true
            encoding_weight: 1.0    // HDC编码时的权重
        },
        {
            key: "project_idea"
            label: "你想做什么项目"
            type: "long_text"
            required: false
            encoding_weight: 0.8
        },
        ...
    ]

    scenario_context: string        // 场景预设上下文，自动注入
}
```

**场景嵌入方式**：

```
黑客松场景为例：

① 主办方与我们合作 → 一起定义 Template（需要填哪些字段）
② 嵌入方式（三选一）：
   - API 对接：主办方系统直接调用我们的注册 API
   - 嵌入组件：iframe / widget 放到报名页面
   - 独立页面：我们托管的注册页面，主办方放链接
③ 参赛者填完信息 → 自动注册 Agent → 进入该场景的网络
④ 场景开始 → 需求广播 → Agent 共振 → 协商
```

#### 7.1.8 完整注册流程

```
Step 1: 选择接入方式
────────────────────────
  a) 我有 SecondMe → SecondMe Adapter（OAuth）
  b) 我要接入 Bot → Bot Adapter（Claude/GPT/...）
  c) 我自己填信息 → Template Adapter（表单）
  d) 我用 API 对接 → Custom Adapter
        ↓
Step 2: 数据采集（各Adapter各自方式）
────────────────────────
  → 收集文本片段 + 元数据
        ↓
Step 3: 画像生成（统一流程）
────────────────────────
  文本片段 → sentence-transformers → SimHash → HDC超向量
  计算 specificity score
  score 低 → 引导补充（不阻止）
        ↓
Step 4: 网络注册
────────────────────────
  存入数据库 → 签发 agent_id + auth_token
  关联到场景（scenario_id）
        ↓
Step 5: 建立连接
────────────────────────
  WebSocket 连接到通爻服务器
  开始接收场景内信号广播
        ↓
Step 6: 激活
────────────────────────
  收到第一个共振信号
  → 用户 Agent：通知用户
  → Bot Agent：自动生成 Offer
```

#### 7.1.9 商业-运营-架构闭环

```
商业策略               运营策略               技术架构
─────────             ─────────             ─────────
场景化切入             找"富上下文"场景       场景准入机制
  │                     │                     │
  ├→ B2B/B2Community   ├→ 与社区/活动合作    ├→ Adapter多源适配
  │                     │                     │
  ├→ 小而密证明价值     ├→ 组织者保障质量      ├→ HDC信息熵检测
  │                     │                     │
  ├→ 成功案例吸引下批   ├→ 口碑传播           ├→ 平台模式快速迭代
  │                     │                     │
  └→ 网络效应后开放     └→ 逐步降低准入门槛    └→ 切换到协议模式

核心飞轮：
场景丰富 → Agent上下文丰富 → 共振精准 → 协商产出好
    → 用户满意 → 口碑 → 更多场景 → ...
```

## 8. 基础设施层问题

> 原 Section 7。

### 8.1 Agent 服务不可用的处理

| 情况 | 处理方式 |
|------|---------|
| 网络超时 | 重试（最多3次） |
| Agent 服务返回错误 | 记录错误，视为"退出" |
| Agent 服务完全不可达 | 标记为"不可用"，视为"退出" |

与 Section 4.4（状态检测）和 Section 10.2 步骤 ⑤（等待屏障）配合：超时 → 未返回的 Agent 标记为"退出"，协商继续。

### 8.2 网络调度与广播

> 2026-02-07 更新：大部分问题已在其他 Section 中解决。

| 原待讨论项 | 现状 |
|-----------|------|
| 信号广播机制 | 已解决 → 见 Section 6.1.7（V1 简单广播，未来语义 Gossip） |
| 并发处理 | 已解决 → 见 Section 10.2（并行 Offer 生成 + 等待屏障） |
| 不同网络速度 | 已解决 → 见 Section 4.4（基础设施层超时）+ Section 4.7（两种部署模式） |
| 文件池设计 | 待定——V1 平台模式下暂不需要独立文件池，需求/Offer 内容通过消息直接传递 |

## 9. 递归触发与子需求

> 原 Section 8。

### 9.1 Gap识别

不需要复杂的Gap识别算法。基于中心Agent的三个决策原则：
1. 能不能满足需求
2. 通过率
3. 效率（发挥价值优先）

告诉大模型我们的流程，以及"递归是一个可选项"，让它自己判断是否需要生成子需求。

### 9.2 渐进式交付

递归不应该阻塞主方案的交付：

```
主方案形成（可能有缺口）
    ↓
先交付主方案，标记缺口
    "这是当前方案，这里有个缺口，正在递归处理，你可以先看其他部分"
    ↓
缺口在后台递归处理（新的协商单元）
    ↓
递归完成 → 补充缺口部分
    ↓
更新方案
```

好处：
- 用户不用一直等
- 如果递归出了问题，主方案不受影响
- 用户可以先对主方案给反馈，同时递归在跑
- 避免"一直等，最后一个地方错了各个地方都错了"

### 9.3 子需求的结构

子需求和主需求是**同构的**（分形结构）：

```python
class Demand:
    demand_id: str
    parent_demand_id: Optional[str]  # 如果是子需求，指向父需求
    content: str
    context: dict  # 包括父需求的信息
    signature: Signature
```

子需求用**完全相同的流程**处理。

### 9.4 递归深度

不硬性限制递归深度。中心Agent在判断时会考虑"当前已经递归了几层"，自行决定是否继续递归还是给出妥协方案。

## 10. Skill 系统

> 原 Section 9。V1 Prompt 草案已迁移到 `docs/prompts/` 目录，本节只保留接口定义。

> 讨论日期：2026-02-06
> 核心认知：**接口是稳定的，提示词是可进化的。** 每个 Skill 定义清晰的接口（角色、职责、输入、输出、原则、生命周期位置），提示词实现可由专门的 SkillPolisher 持续优化。

### 10.1 设计理念

Skill 本质上是**启用一个子 Agent**。每个 Skill 封装一种能力，包含接口定义和提示词模板。

**两层分离**：

| 层次 | 内容 | 稳定性 | 谁负责 |
|------|------|--------|--------|
| 接口层 | 角色、职责、输入/输出、原则、约束 | 稳定（架构级） | 架构师 |
| 实现层 | 具体提示词、few-shot 示例、CoT 引导 | 可进化 | SkillPolisher |

**两种 Skill 类型**：

- **统一 Skill**：所有实例用同一套逻辑（CenterCoordinator、SubNegotiation、GapRecursion）
- **可定制 Skill**：每个 Agent 有自己的版本（ReflectionSelector、OfferGeneration）

### 10.2 协商流程中的 Skill 调用（程序层 + 能力层）

> 核心原则：**凡是能用代码保障的，绝不用 prompt 保障。** 确定性逻辑交给代码，需要智能的部分交给 LLM。
> 研究支撑：Microsoft Magentic Marketplace（2025）发现 LLM 有严重的第一提案偏见（10-30x），但这在程序层可彻底消除。

```
程序层（代码控制，确定性）          能力层（LLM，非确定性）
─────────────────────           ─────────────────────

① 用户表达意图
     ↓
② 需求 formulation（可插拔）     → 用户 Agent 丰富化需求
   用户确认 → 编码为 HDC 签名        （基于 Profile、上下文）
     ↓
③ HDC 共振检测（代码）
   → 得到激活的 Agent 列表
     ↓
④ 并行调用所有激活的 Agent        → OfferGenerationSkill
   每个 Agent 独立生成 Offer         （每个Agent各自调用）
     ↓
⑤ 等待屏障（Barrier）——代码控制
   所有 Offer 都返回（或 Agent 主动退出）→ 继续
   基础设施层故障检测 → 不可达的 Agent 标记为"退出"
     ↓
⑥ 组装完整输入 + 工具集           → CenterCoordinatorSkill
   调用 Center（tool use 模式）       （Center 自由选择工具）
     ↓
⑦ 执行 Center 的工具调用（代码）
     Center 调用了什么，程序层就执行什么：
     · output_plan(...)          → 输出方案，协商终止
     · create_machine(...)       → Machine 上链（draft）→ 执行阶段（Section 11）
     · ask_agent(...)            → 转发追问，收到回复 → 回到 ⑥
     · start_discovery(...)      → 调用 SubNegotiationSkill，结果回流 → 回到 ⑥
     · create_sub_demand(...)    → 启动新协商单元 → 回到 ①（递归）
     · （可组合：Center 可一次调用多个工具）
     ↓
⑧ 轮次计数器（代码控制）
   超过 2 轮 → 限制工具集为 output_plan / create_machine
```

**关于方案确认**（2026-02-07 决策）：

"确认"不是独立步骤，而是协商的自然终止态。Agent 面对方案只有三种穷举状态：有异议（继续协商）、退出、无异议（即确认）。方案输出后的通知、分类、展示属于应用层——用户可自定义（如：高优先级直接推送、中优先级网站留言、低优先级存档自查）。

**设计决策的研究支撑**：
- **最多 2 轮**：Google DeepMind（2025）发现多轮迭代平均效果 -3.5%，错误放大 4.4x
- **并行收集 + 聚合**：Mixture-of-Agents（2024）验证 Proposer→Aggregator 是最优架构
- **等待屏障**：对抗第一提案偏见的结构性保障（代码层，非 prompt 层）
- **元认知提示**：Emergent Coordination（2025）发现 persona + metacognition 产生真正的集体智能
- **观察遮蔽**：JetBrains Research（2025）发现遮蔽比摘要更好，成本低 50%

### 10.3 Skill 清单与生命周期位置

| Skill | 类型 | 生命周期位置 | 职责 |
|-------|------|------------|------|
| **DemandFormulationSkill** | 可定制 | 协商流程 ② | 丰富化用户需求，编织偏好进HDC签名（可插拔） |
| **ReflectionSelectorSkill** | 可定制 | 注册时 / 数据变更时 / 协商后 | 生成和维护 Agent 的 HDC 超向量画像 |
| **OfferGenerationSkill** | 可定制 | 协商流程 ④ | 基于 Agent 真实 Profile，诚实回应需求 |
| **CenterCoordinatorSkill** | 统一 | 协商流程 ⑥ | 综合所有 Offer，规划最优方案 |
| **SubNegotiationSkill** | 统一 | 协商流程 ⑦（Center 触发） | 发现性对话，激发隐藏上下文 |
| **GapRecursionSkill** | 统一 | 协商流程 ⑦（Center 触发） | 将缺口转化为子需求，触发递归 |

### 10.4 DemandFormulationSkill（需求丰富化器）

> 2026-02-07 新增。

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | 用户真实需求的理解者和表达者 |
| 职责 | 基于用户 Profile 和上下文，将原始意图丰富化为更准确的需求表达 |
| 输入 | 用户原始意图 + Agent 的 Profile Data |
| 输出 | 丰富化后的需求文本（供 HDC 编码和广播） |
| 原则 | ① 理解"要求"背后的"需求"（张力） ② 保留用户意图，补充上下文而非替换 ③ 丰富化程度由用户控制 |
| 约束 | 输出需经用户确认后才广播；这是可插拔扩展点，用户可自定义丰富化逻辑 |
| 调用时机 | 协商流程 ②，用户表达意图后 |

> V1 Prompt 草案见 `docs/prompts/demand_formulation_v1.md`

### 10.5 ReflectionSelectorSkill（画像投影器）

> **2026-02-07 架构简化**（Design Log #003）：原名"画像生成器和维护者"，现更名为"画像投影器"。Agent 画像不是维护的，而是从 ProfileDataSource 投影出来的。不再有"经验生长"——协作数据回流到数据源，重新投影时自然反映。

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | Agent 画像的投影执行者 |
| 职责 | 从 ProfileDataSource 读取数据，通过投影函数生成 HDC 超向量 |
| 输入 | ProfileDataSource 提供的 ProfileData + 透镜（lens）参数 |
| 输出 | HDC 超向量画像（10,000 维二进制，1.25KB） |
| 原则 | ① 画像应反映真实能力和经历，不应被美化 ② 投影是无状态函数，不存储中间状态 |
| 约束 | 共振检测本身不消耗大模型 token |
| 调用时机 | 注册时（初始投影）/ 数据源变化时（重新投影）/ 需要时按需计算（可缓存） |

**处理流程**：

```
输入：ProfileDataSource.get_profile(user_id) → ProfileData
    ↓
1. 提取关键特征文本
2. 编码器（sentence-transformers）→ 语义向量
3. SimHash → HDC 超向量
4. 捆束(bundle) → Agent 综合画像 = project(profile_data, lens)
    ↓
输出：HDC 超向量画像（投影函数的结果，无状态）
    ↓
部署到端侧：Hamming 距离计算（< 100ns，不调用大模型）
```

**画像演化**：不再通过 Random Indexing 直接融入 Agent 画像。协作数据回流到 ProfileDataSource（见 Section 7.1.6），下次投影时自然反映更新。

### 10.6 OfferGenerationSkill（端侧响应生成器）

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | Agent 在协商中的发言人 |
| 职责 | 基于 Agent 的真实 Profile，对需求给出诚实的回应 |
| 输入 | 需求文本 + Agent 自己的 Profile Data |
| 输出 | Offer（我能贡献什么、我有什么相关经历） |
| 原则 | ① 只描述 Profile 中记录的能力和经历（不捏造）② 说清楚哪些相关、哪些不相关 ③ 元认知：考虑自己可能有的意想不到的价值 |
| 约束 | Prompt 中只包含该 Agent 自己的 Profile Data，没有其他 Agent 的信息 |
| 调用时机 | 协商流程 ④，被 HDC 共振激活后 |

**防止捏造的多层保障**：

| 层次 | 机制 | V1 是否实现 |
|------|------|-----------|
| Prompt 约束 | 指令中明确"只描述 Profile 中记录的" | ✅ |
| 信息源限制 | Prompt 中只包含该 Agent 的 Profile Data | ✅ |
| 事实校验 | 生成后自动检查声明是否有 Profile 依据 | V2+ |

> V1 Prompt 草案见 `docs/prompts/offer_generation_v1.md`

### 10.7 CenterCoordinatorSkill（中心综合规划器）

> 2026-02-08 重写。Center 从"分类输出"改为"工具调用"模型。见 Section 3.4。

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | 多方资源综合规划者 |
| 职责 | 综合所有 Offer，用工具推进协商 |
| 输入 | 需求文本 + 所有 Offer（程序保障完整性）+ 用户偏好/约束 + 历史（如有，观察遮蔽格式） |
| 工具集 | `output_plan` / `create_machine` / `ask_agent` / `start_discovery` / `create_sub_demand`。见 Section 3.4 |
| 核心规则 | 评估当前 Offer 能否满足需求，用工具推进协商 |
| 原则 | ① 满足需求 ② 通过率（各方会不会同意）③ 效率 |
| 元认知 | 考虑互补性、意外组合、反锚定 |
| 约束 | 只在所有 Offer 到齐后被调用（代码保障）；历史采用观察遮蔽；超过 2 轮时工具集被限制为 output_plan / create_machine |
| 调用时机 | 协商流程 ⑥，等待屏障通过后 |

**历史管理（观察遮蔽）**：

```
第 1 轮：Center 看到需求 + 所有原始 Offer
第 2 轮：Center 看到：
    - 需求（保留）
    - 第 1 轮的 reasoning 和 decision（保留）
    - 第 1 轮的原始 Offer（遮蔽为："共收到N个Offer，来自A/B/C"）
    - 第 2 轮的新回复（原文）
```

> V1 Prompt 草案见 `docs/prompts/center_coordinator_v1.md`

### 10.8 SubNegotiationSkill（发现性对话）

> 核心认知：P2P 不是"辩论"（双方拿相同信息争论，研究证实效果为负），而是"发现性对话"（双方各自有不同的深层信息，对话激发新信息）。端侧 Agent 持有独特的 Profile / SecondMe 上下文，初始 Offer 不一定覆盖所有相关能力。对话可以激发"我没想到的、但实际上我有的"价值。

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | 双方隐藏价值的发现者 |
| 职责 | 通过引入 Profile 上下文，发现 Offer 中未提及的关联和互补 |
| 输入 | 触发原因 + Agent A 的 Offer 和 Profile + Agent B 的 Offer 和 Profile |
| 输出 | 发现报告（新发现的关联、协调方案、各方可能的额外贡献） |
| 原则 | ① 不是裁决谁对谁错，是发现双方还没说出的价值 ② 关注 Profile 中 Offer 未涉及的部分 |
| 约束 | V1 由第三方 LLM 综合判断（一次调用）；未来可扩展为端侧 Agent 直接对话 |
| 调用时机 | 协商流程 ⑥，Center 判断需要 P2P 时触发 |

**V1 方案（第三方综合）与未来方案（端侧对话）**：

```
V1：第三方综合（一次 LLM 调用）
    输入：冲突/互补描述 + A的Offer + A的Profile + B的Offer + B的Profile
    LLM 综合判断 → 发现报告
    → 简单、可控、避免辩论负效应

未来：端侧 Agent 对话
    A 和 B 各自看到对方的 Offer + 冲突描述
    A 基于自己的 SecondMe 上下文回应
    B 基于自己的 SecondMe 上下文回应
    → 更丰富，能激发出 V1 无法发现的深层关联
    → 需要控制轮次（最多 1-2 轮）避免错误传播
```

> V1 Prompt 草案见 `docs/prompts/sub_negotiation_v1.md`

### 10.9 GapRecursionSkill（子需求生成器）

**接口定义**：

| 项目 | 内容 |
|------|------|
| 角色 | 缺口到子需求的转换器 |
| 职责 | 将 Center 识别的缺口转化为可独立处理的子需求 |
| 输入 | 缺口描述 + 父需求 context |
| 输出 | 子需求文本（进入同样的协商流程，递归） |
| 原则 | ① 子需求应该比父需求更具体 ② 子需求应该是自包含的（不依赖父协商的内部状态） |
| 约束 | 子需求携带父需求 context，让共振检测更精准 |
| 调用时机 | 协商流程 ⑥，Center 判断有缺口时触发 |

> V1 Prompt 草案见 `docs/prompts/gap_recursion_v1.md`

### 10.10 Skill 优化机制（SkillPolisher）

**设计思路**：每个 Skill 的接口是稳定的架构合约，提示词实现是可持续优化的。

```
SkillPolisher 的工作流程：
    1. 阅读 Skill 的接口定义（角色、职责、输入、输出、原则）
    2. 阅读当前的 V1 Prompt 草案
    3. 基于实际运行数据（Offer 质量、方案质量、用户反馈）
    4. 提出优化后的 Prompt
    5. A/B 测试 → 验证优化效果 → 更新 Prompt

优化维度：
    - 更精准的 prompt 用词和结构
    - 更好的 chain-of-thought 引导
    - 针对特定模型的优化（Claude vs GPT vs 开源）
    - 边界条件处理（空输入、极端场景）
    - few-shot 示例的添加和选择
    - 不同场景模板的适配
```

**约束**：SkillPolisher 不能改变 Skill 的接口定义，只能优化实现层。接口变更需要架构讨论。

## 11. 执行与回声阶段

### 11.1 问题背景：系统缺少反馈循环

**发现的根本问题**（2026-02-07）：

系统只有"波出去"（需求广播、协商、方案生成），没有"波回来"（执行反馈）。这导致：
- Agent Profile 无法从真实结果中学习和演化
- 系统不知道自己是否真正 work（价值信号缺失）
- 无法区分"说得好"和"做得好"

**错误方向**：用 LLM 判断"方案是否被采纳" = LLM 判断 LLM = 幻觉循环

**正确方向**：真实世界的执行信号（区块链上不可伪造的协作数据）

类比抖音推荐：不是看 LLM 说"用户喜欢"，而是看真实的点赞、评论、转发、停留时长。

### 11.2 解决方案：WOWOK 区块链集成

**WOWOK** 是 AI 驱动的 Web3 协作协议（Sui 区块链），提供完整的链上执行基础设施。

**9 个核心对象**：
- **Personal**：链上身份
- **Demand**：需求发布
- **Service**：服务/产品门户（包含承诺、价格、workflow）
- **Machine**：workflow 模板定义（本质）
- **Progress**：workflow 执行实例（实现）
- **Order**：交易实例
- **Guard**：验证引擎（定义条件，不是签名本身）
- **Treasury**：支付管理
- **Repository**：交付物存储

**通爻与 WOWOK 的关系**：
- **通爻（ToWow）**：发现与协商（发波）
- **WOWOK**：执行与验证（回波）
- **集成点**：Center 输出的方案 → WOWOK Machine/Service → 链上执行 → 回声信号

### 11.3 回声信号的本质

**核心机制**：

```
WOWOK 链上每个操作都留下数据
         ↓
协作数据是全息的（Forward、Order、Progress、Treasury）
         ↓
数据回流到通爻 → 更新 Agent Profile
         ↓
更新后的 Profile 指导下次协商
         ↓
闭环：发波 → 回波 → 演化 → 再发波
```

**设计原则**：

1. **不预设信号重要性**
   - 所有链上事件都是潜在信号源
   - 重要性从 Agent 与事件的共振中涌现
   - 不同 Agent 对同一事件的感知不同

2. **投影是基本操作**（与设计原则 0.8 一致）
   - 链上事件（全息）→ 多维特征（投影）
   - 特征 → HDC 向量（投影）
   - 向量 → Agent 感知（投影）
   - 同一个操作在不同层次重复

3. **场广播，端侧检测**
   - 事件不是点对点发送
   - 事件向场中广播扰动
   - Agent 在端侧感知与自己共振的扰动

4. **本质与实现分离**（与设计原则 0.2 一致）
   - 本质：回声 = 数据回流 → Profile 更新
   - 实现：可以是 HDC、可以是其他编码；可以是 Pub/Sub、可以是 Gossip

**回声信号的来源**：

- **链上事件**：OnNewOrder（购买）、OnNewProgress（进展）、OnPresentService（推荐）、OnNewArb（仲裁）
- **Forward 操作**：每个 workflow 推进都携带数据（deliverable.msg、deliverable.orders）
- **状态变化**：Progress 节点迁移、Guard 验证结果
- **资金流动**：Treasury 转账、结算
- **关键**：这些不是分离的"事件类型"，而是同一个全息协作数据在不同维度的投影

### 11.4 关键架构决策

#### 11.4.1 Machine Template 策略

**不预设 Template 库**，建立沉淀机制：

- **V1 启动**：Guidelines（本质描述）+ MCP 实时获取 WOWOK 实现 → LLM 生成 Machine JSON
- **运行积累**：成功执行的 Machine 自动沉淀到 Template 池
- **后续复用**：类似需求优先检索已有成功案例，微调复用
- **克隆机制**：Machine 本质是 JSON 文件，可以克隆修改

**Machine 生命周期**：
1. 创建（上链，bPublished=false，可修改）
2. 参与方确认、测试
3. 发布（bPublished=true，不可修改）
4. 创建 Service（使用已发布的 Machine）

**原因**：
- 灵活性：任何需求都能适配
- 自动同步：MCP 获取的是最新 WOWOK 实现
- 符合本质/实现分离：Guidelines = 本质，MCP = 实现
- Template 是涌现的结果，不是预设的约束

#### 11.4.2 Service 创建时机

**WOWOK Service** vs **通爻 Service Agent**（两个不同概念）：

- **WOWOK Service**：链上的单次业务合约（绑定 Machine、价格、Guards）
- **通爻 Service Agent**：长期角色，从 Edge Agent 分化的专才投影

**Service 创建流程**：
```
协商阶段：Center 生成 plan（文本）+ Machine JSON（草稿）
         ↓
确认阶段：参与方确认承诺（Machine 上链但未发布）
         ↓
发布阶段：Machine.publish() → bPublished = true
         ↓
创建阶段：创建 WOWOK Service（使用已发布的 Machine）
         ↓
执行阶段：参与方购买 Service → Order → Progress
```

**关键**：上链 ≠ 承诺，发布 = 承诺。提供了"确认缓冲期"。

#### 11.4.3 Progress 绑定策略

**Progress.task_address** 是可选的外部关联（一旦设置不可解绑）。

**不预设绑定规则**，而是描述本质，让 LLM 根据场景判断：

- **是什么**：Progress 与外部对象的可选关联
- **效果**：外部系统可以通过 task_address 查询 Progress 状态，构建依赖图
- **考虑**：是否需要与外部对象建立持久关联？是否需要追溯到具体业务实体？

**可能的绑定选择**：
- 绑定 Order：Service 购买场景
- 绑定上游 task：企业内部供应链管理
- 不绑定：纯 workflow 执行

**原因**：符合"智能在 LLM，约束在代码"原则。代码定义可能性空间，LLM 从理解中投影出决策。

#### 11.4.4 支付问题考量

**识别为复杂的多维度问题**（暂不解决，标识为子课题）：

涉及维度：
- **法律**：国内加密货币监管
- **商业**：运营主体、资金流、税务
- **用户心理**："把钱放到区块链"的恐惧
- **技术**：如何获得真实的回声信号
- **运维**：支付对账、纠纷处理

**V1 务实策略**：
- 使用"信用额度"或"模拟货币"（不涉及真实支付）
- 回声信号 = 信用变化（链上记录，不可伪造）
- 目标：证明核心机制有效

**未来探索方向**：
- 链下支付 + 链上凭证
- 积分/信誉系统 + 周期性结算
- 支付宝/微信 MCP 集成（状态待确认）

#### 11.4.5 V1 实现策略

**不要模拟层，直接用 WOWOK**：

```
通爻网络
     ↓
WOWOK MCP (本地)
     ↓
Sui 本地测试网/开发网
```

**原因**：
- 避免重复造轮子（两套实现：PostgreSQL 模拟 + WOWOK 真实）
- MCP server 可以本地运行（TS 代码，可调试）
- V1 → V1b 只是切换网络（devnet → testnet → mainnet）

**保留轻量级抽象**（EchoSource）：
```python
class EchoSource:
    """回声信号源的抽象接口"""
    def subscribe(self, callback): ...

class WOWOKEchoSource(EchoSource):  # 真实实现
    def __init__(self, mcp_client): ...

class MockEchoSource(EchoSource):  # 测试实现
    # 用于测试 Profile 更新逻辑，不需要真的上链
```

### 11.5 需要深入研究的子课题

以下是需要单独深入的子课题（不在架构文档展开）：

1. **HDC 编码策略**
   - 不同类型数据（时间、关系、语义、金额）如何编码？
   - 如何保持语义相似性？
   - 需要：文献调研 + 实验验证

2. **投影维度设计**
   - 哪些维度是必要的？（temporal, relational, semantic, structural, economic...）
   - 维度之间如何平衡权重？
   - 需要：场景分析 + 用户研究

3. **共振阈值策略**（关联 Task #2）
   - 阈值怎么设？动态调整还是固定？
   - 不同 Agent 的阈值是否不同？
   - 需要：冷启动策略 + 反馈循环设计

4. **~~Profile 更新算法~~** → **已简化**（Design Log #003）
   - ~~Random Indexing 的具体参数（学习率、衰减率）？~~
   - ~~如何避免 Profile 漂移？~~
   - 投影即函数：通爻不维护 Profile 状态，协作数据回流到 ProfileDataSource，数据源自己处理更新
   - **残留问题**：ProfileDataSource 的同步策略（实时 vs 批量？数据源不可用时的降级？）
   - 详见 Section 7.1.6 和 Design Log #003

5. **工程实现与性能**
   - 场广播的具体机制（Pub/Sub？Gossip？）
   - HDC 计算的性能优化（并行化？硬件加速？）
   - 存储策略（全量？增量？）
   - 需要：工程实验 + 压力测试

### 11.6 反脆弱设计考虑

**核心思想**：设计让失败也产生价值。

**可能的失败模式与应对**：

| 失败模式 | 失败后能得到什么 | 反脆弱设计 |
|---------|----------------|----------|
| HDC 编码效果不如预期 | 协作数据、场景标签、真实需求样本 | 数据结构支持多种编码，可替换 |
| 共振阈值设置不当 | Agent 响应行为数据、误报/漏报分布 | 可调参数，A/B 测试 |
| 回声信号噪音太大 | 哪些信号有价值、哪些是噪音 | 分层过滤，可调整权重 |
| WOWOK 链上成本太高 | 哪些操作必须上链、哪些可以链下 | ExecutionAdapter 抽象，可切换实现 |
| 用户不理解 Machine 概念 | 用户真实的心智模型 | 前端 UI 可重新设计，Machine 本质不变 |

**反脆弱策略**：
- **可观测性**：记录所有关键指标（共振次数、响应率、协商成功率）
- **可回退性**：保留简单方案作为 baseline（如 HDC 不行，回退到标签匹配）
- **数据沉淀**：即使功能失败，数据也为下一版提供输入
- **渐进式引入**：不一次性切换，留下对比基准

#### 失败模式全景分析（2026-02-08，Task #6）

**核心发现**：系统最需要防御的不是"出了错怎么办"，而是"错了你不知道"。区分静默失败（无感知）和响亮失败（有反馈）是关键。

| 失败模式 | 静默/响亮 | 在哪层解决 | V1 策略 |
|---------|----------|----------|--------|
| HDC 假阴性（漏掉好匹配） | **静默** | 实现层（编码质量、向量维度） | 阈值宁低勿高；事后宽阈值重跑做 A/B 对比 |
| 需求 formulation 失真 | **静默** | 产品层（多轮对话追问） | DemandFormulationSkill 追问机制 + 用户确认可迭代 |
| 回声信号误归因 | **静默** | 产品层（用户确认） | 回声数据缓存待确认（"你有新记忆，是否添加？"）；用户完全控制自己数据 |
| Offer 质量崩溃 | 响亮 | 产品层 + 程序层 | Center 允许说"没找到"；展示搜索过程和失败原因；程序层 Offer 最低门槛 |
| 递归失控 | 响亮 | 程序层（已解决） | 轮次硬上限（当前 2 轮，可测试调整）；递归深度上限 |
| 冷启动 | 响亮 | 生态层（已解决） | SecondMe 数据种子 + Template Adapter + 场景驱动积累 + 市场价格机制 |

**关键结论**：
1. **没有需要在协议/架构层新增的机制** — 架构基本面健康
2. 静默失败通过**可观测性**检测（→ Task #12），通过**产品层 UX** 缓解（用户确认、展示过程）
3. 响亮失败已被现有机制覆盖（硬上限、用户确认、市场自调节）
4. HDC 假阴性是唯一的纯技术风险 — 属于 HDC 编码子课题（见 11.5.1），不是架构问题
5. **"失败也是信息"** — 即使协商失败，也应该告知用户过程和原因（搜索过谁、讨论过什么），让失败也有价值

### 11.7 可观测性框架（2026-02-08，Task #12）

**核心原则**：协议定义"记录什么"，实现决定"怎么存怎么看"。不预定义 100 个 KPI——记录完整追溯链，指标是查询。

**协商追溯链**（每个协商单元完成后产生一条完整记录）：

```
协商 #<unique_id>
├── 需求 formulation
│   ├── 用户原始输入
│   ├── formulation 输出（HDC 签名 + 丰富化描述）
│   └── 用户确认（直接确认 / 修改 N 次）
├── 共振阶段
│   ├── 广播范围（场景 + Agent 数量）
│   └── 各层通过数（Tier 1 / Tier 2 + 共振分数 / Tier 3）
├── Offer 收集
│   ├── 收到的 Offer（内容 + 生成耗时 + token 数）
│   └── 等待屏障结果（全部返回 / 有 Agent 主动退出 / 有进程故障）
├── Center 综合
│   ├── 工具调用记录（用了哪些工具、参数、结果）
│   ├── 轮次数
│   └── 输出（plan / machine_draft / 触发子协商等）
├── 结果
│   ├── 用户反馈（接受 / 拒绝 / 修改）
│   └── 执行关联（Machine ID → 后续回声信号）
└── 元数据
    ├── 总耗时、LLM 调用成本
    ├── 快照版本号
    └── 参数版本（阈值、prompt 版本——支持 A/B 测试）
```

**关键指标（从追溯链查询推导）**：

| 指标 | 怎么算 | 衡量什么 |
|------|-------|---------|
| 共振精准率 | Tier 2 通过 Agent 中 Offer 被 Center 采纳的比例 | HDC 匹配质量 |
| 意外发现率 | 最终方案中用户没有明确要求的参与者比例 | **核心价值指标**——响应范式 vs 搜索范式的差异 |
| Offer 采纳率 | Center 使用的 Offer 数 / 收到的 Offer 数 | Offer 生成质量 |
| 方案接受率 | 用户接受数 / 总方案数 | Center 综合质量 |
| Formulation 修改率 | 用户修改次数分布 | 需求理解质量 |
| 执行成功率 | 正面回声 / 总回声 | 端到端质量 |
| 协商成本 | 每个成功协商的 LLM 成本 | 效率 |

**V1 最小实现**：每个协商写一个 JSON log（上述结构），一个脚本做聚合查询。仪表盘、告警、自动化 A/B 是后续的事。

### 11.8 工程验证路线

**V1（最简单版本）**：
- 只监听关键事件（OnNewOrder、OnNewProgress）
- 用最简单的方式更新 Profile（计数器？标签集合？）
- 目标：证明"回声循环"可以跑通

**V1b（引入 HDC）**：
- 替换为 HDC 编码
- 对比效果：HDC 是否真的比简单方法好？
- 目标：验证 HDC 的实际价值

**V2（完整投影架构）**：
- 多维投影、动态权重、自适应阈值
- 目标：达到"发现未知关联"的能力

**关键**：每一步都要验证，不是"想象有用"，而是"测量有用"。

### 11.9 相关设计文档

- `docs/DESIGN_LOG_002_ECHO_AND_EXECUTION.md`（详细设计日志，待修订）
- WOWOK 对象文档：`/Users/nature/个人项目/wowokWeb/docs/docs/object/`
- WOWOK MCP servers：npm 包 `wowok_*_mcp_server`

## 12. 经济与激励模型方向

> 2026-02-08 新增（Task #4）。原则级方向，非详细设计。
> 核心判断：**经济模型是商业问题，不影响架构设计。** 架构已内建支撑经济模型的所有基础能力。

### 12.1 核心原则

**协议不赚钱，基于协议的产品赚钱。** 类比：TCP/IP 不收费，但互联网上的服务创造了巨大商业价值。OpenAI 从非营利起步，协议层的普及先于商业化。

### 12.2 V1 成本模型

- **主要成本**：人才（科学家、工程师解决核心技术问题），不是算力
- **LLM 调用成本**：每次协商 ~$0.15-0.30，V1 规模下可忽略
- **资金来源**：天使轮/种子轮投资
- **策略**：平台全额补贴，不引入付费摩擦。V1 目标是证明机制有效

### 12.3 Agent 参与激励

不单独设计激励机制，而是通过生态联动自然产生：

- **参与即成长**：协作 → 回声信号 → Profile 更丰富 → 未来被发现概率更高
- **生态伙伴**：与 SecondMe、A2A 生态、Bot Agent 平台、社区联合运营
- **开发者生态**：通爻作为协作基础设施，开发者在其上构建应用

### 12.4 长远方向

**产品赋能引擎**：通爻技术嵌入到各种产品中，为其提供协作能力

- 为黑客松提供更好的匹配 → 场景服务费
- 为企业提供内部协作 → 企业服务
- 为社区提供连接 → 社区合作
- 协议普及后，基于协议的产品（我们的或第三方的）实现商业化

**协议模式的经济自洽**：未来从平台模式切换到协议模式后，端侧自付 LLM 成本（Agent 自己为自己的投影和 Offer 生成买单）。

### 12.5 架构已内建的经济基础能力

| 经济需求 | 架构支撑 |
|---------|---------|
| 端侧付费 | 平台模式 → 协议模式路径已设计（Section 7.1.1） |
| 用户数据所有权 | ProfileDataSource 可插拔，数据在源头（Section 7.1.6） |
| 价值追踪 | WOWOK 链上执行 + 回声信号（Section 11） |
| 参与即成长 | 回声 → 数据回流 → 重新投影（Section 7.1.6 + 11.3） |
| 声誉系统 | 回声信号的自然积累，不需要额外设计 |

### 12.6 相关方向：个人数据主权（第二项目）

> 标记为探索方向，不在本项目架构范围内。

可插拔、可携带、跨场景、跨应用、跨平台、跨终端的个人数据存储——用户拥有自己数据的所有权。与通爻的 ProfileDataSource 接口天然关联：这个"个人数据主权"项目就是 ProfileDataSource 的一个 Adapter 的实体化。

可能的实现方向：区块链（链上凭证）、端侧硬件（本地计算）、或两者结合。需要单独深入探讨。

## 13. 待讨论的问题

> 原 Section 12（重新编号）。

- [x] 签名广播机制：签名包含什么？如何广播？→ 见 Section 6.1 签名共振机制
- [x] 端侧筛选机制：如何低能耗判断是否响应？→ 见 Section 6.1.3 三层共振过滤架构
- [x] Agent接入机制：如何让用户接入自己的Agent？→ 见 Section 7.1 Agent接入机制
- [x] 网络调度中心设计：V1简单广播，未来语义Gossip → 见 Section 6.1.7
- [x] 各Skill的提示词设计 → 见 Section 10.2-10.10 Skill 系统（接口定义 + SkillPolisher 机制）；V1 Prompt 草案见 `docs/prompts/`
- [x] 架构一致性审视（2026-02-07）→ Section 3/5 重写与 Section 10 对齐；需求formulation 替代需求方筛选（见 1.2）；方案确认为协商自然终止态（见 10.2）；设计原则提升到 Section 0
- [x] "自-我"工程映射与 Service Agent 模型（2026-02-07）→ 见 Section 1.3；设计原则 0.8/0.9/0.10；Design Log: `docs/DESIGN_LOG_001_PROJECTION_AND_SELF.md`
- [x] 场景独立定义（2026-02-07）→ 见 Section 1.4；V1 定位：商业入口 + 数据收集
- [x] 事件语义更新（2026-02-07）→ 见 Section 3.5；新增 demand.formulate，取消 plan.distribute / response.confirm 作为独立事件
- [x] AgentIdentity 数据结构更新（2026-02-07）→ 预留 agent_type、parent_id 字段
- [x] Section 8 更新（原 Section 7，2026-02-07）→ 大部分已在其他 Section 解决，标注引用
- [x] 执行与回声阶段（2026-02-07）→ 见 Section 11；WOWOK 集成架构、Machine Template 策略、Service 创建时机、Progress 绑定策略、支付问题考量、反脆弱设计
- [x] Section 6 拆分重组（2026-02-07，Task #14）→ 已完成：6.1/6.2/6.4 合入 Section 4；6.3 独立为 Section 6（HDC 签名与共振检测）；6.5 独立为 Section 7（Agent 接入与 Profile 管理）；V1 Prompt 草案迁移到 `docs/prompts/`
- [ ] HDC编码器的具体选型与benchmark → 标识为子课题（见 11.5.1）
- [ ] 共振阈值(θ)的调优策略 → 标识为子课题（见 11.5.3）
- [x] Profile 更新算法与参数 → Design Log #003 架构简化：投影即函数，通爻不维护 Profile 状态。残留问题：ProfileDataSource 同步策略（见 11.5.4 更新）
- [ ] SecondMe数据同步的具体协议
- [x] Center Agent 决策逻辑审视（2026-02-08，Task #13）→ 从 5 种输出类型改为工具调用模型。Center 不是分类器，是拿着工具集的 Agent。plan/contract 合并为同一产出物的不同成熟度。见 Section 3.4/3.5/10.2/10.7
- [x] 透镜本质定义（2026-02-08，Task #3 收尾）→ 透镜 = 维度选择器。架构层定义完成，实现细节标记为子课题。见 Section 7.1.6
- [x] 经济与激励模型方向（2026-02-08，Task #4）→ 原则确立：协议不赚钱，产品赚钱；V1 投资支撑；激励 = 生态联动 + 参与即成长；架构不受影响。见 Section 12
- [x] 时间语义与并发一致性（2026-02-08，Task #5）→ 原始问题"时间怎么流"是伪问题，重构为并发一致性。产出：设计原则 0.11（快照隔离）和 0.12（投影不承诺，人承诺）。大部分"并发问题"被架构本质消解——Agent 是投影不是行为者，双重承诺是人的问题，马太效应有市场机制平衡。V1 真正需要解决的：快照隔离 + 幂等性（唯一 ID 去重）。场景不是容器，是上下文标签，不需要生命周期管理。
- [x] 失败模式全景分析（2026-02-08，Task #6）→ 6 个失败模式按"静默/响亮"分类。核心发现：没有需要新增的架构机制，架构基本面健康。静默失败（HDC 假阴性、formulation 失真、回声误归因）通过产品层 UX 和可观测性解决；响亮失败（Offer 质量、递归、冷启动）已被硬上限/市场机制/用户确认覆盖。见 Section 11.6 失败模式全景分析。
- [x] 安全模型与数据所有权（2026-02-08，Task #11）→ 无需新增安全机制，安全从设计原则自然涌现。数据所有权 = ProfileDataSource 外置；访问控制 = 透镜即授权；Agent 无行动权限 = 攻击面极小；HDC 天然有损无法精确反推；防伪造 = 链上信誉（WOWOK 记录不可篡改，作恶有证据，可举报，想重来只能清零从头开始）；准入 = 场景组织者自治。DID 非必要——问责通过链上记录自然实现。
- [x] 可观测性框架（2026-02-08，Task #12）→ 协议定义"记录什么"，实现决定"怎么存怎么看"。核心：每个协商单元产出完整追溯链（JSON log），指标是查询而非预定义。关键指标：意外发现率（核心价值指标）、共振精准率、Offer 采纳率、方案接受率。V1 最小实现：JSON log + 查询脚本。同步修正：等待屏障不含协议层超时——超时是基础设施层故障检测。见 Section 11.7。

---

*最后更新：2026-02-08（第十一轮：文档结构优化收尾——11.8 编号修复；非功能需求不单设章节（已散落在正确位置）；全部原始讨论课题已关闭）*
