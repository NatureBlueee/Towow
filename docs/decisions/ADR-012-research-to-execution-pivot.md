# ADR-012: 从研究到执行的转向 — 编码层用别人的，查询层用自己的

**日期**: 2026-02-16
**状态**: 已批准
**关联**: ADR-011 (V2 Intent Field), Genome v0.3 §6/§10, 研究 000/001/002

---

## 背景

V2 Intent Field 模块已实现（76 测试，10 文件，~1000 LOC）。四轮实验（Phase 0-4）完成。两轮学术研究完成（研究 001: 多关系编码，研究 002: 实验技能设计）。

研究发现了一个关键修正：匹配不是"从 Agent 画像找到响应需求的人"（异质匹配），而是"从意图中找到相关的意图"（**Intent-to-Intent 同质匹配**）。三种"相关"：共振、互补、干涉。

研究同时确认了两件事：
1. **编码层有大量现成技术可用**：BGE-M3、Qwen3-Embedding、MRL+BQL 等，比我们的 mpnet+SimHash 更优且直接可用
2. **互补/干涉关系的编码层方案（GHRR、双曲空间等）全部是前沿研究**，没有成熟可用的

这产生了一个关键判断：在编码层花时间研发多关系编码 vs 在查询层用 LLM 生成多视角查询。

---

## 核心洞察

### 编码层解决不了的问题，查询层一行代码就能解

向量相似度只能找"像"的东西。但如果你能用 LLM 把"我缺什么"翻译成"谁有什么"，然后用同一个向量空间找相似——互补关系就退化成了相似性查找。

```
共振：直接匹配（现有能力）
互补：LLM("我缺什么" → "谁有什么") → 匹配
干涉：LLM("深层关联视角") → 匹配
```

**一次 LLM 调用，解决了 GHRR 论文几十页数学试图解决的问题。**

这正是 Genome v0.3 §6 说的 Formulation 透镜的真正位置：**不在匹配管道里改善精度，在匹配之前扩展查询视角**。Phase 2 证明 formulation 不改善单次匹配精度——但多视角生成不是改善精度，是生成新的查询方向。完全不矛盾。

### Intent-to-Intent 不需要新轮子

底层技术（embedding + 向量检索）和 query-to-document 完全一样。区别在协议层定义：两边走同一条编码路径，存同一个场。这是**设计创新，不是技术创新**。

---

## 决策

### 决策 1：编码层全部用现成技术

| 组件 | 当前 | 替换为 | 理由 |
|------|------|--------|------|
| 编码器 | mpnet-768d (2021) | BGE-M3-1024d 或 Qwen3-Embedding | 2024 SOTA，原生多语言，MRL 支持 |
| 二值化 | SimHash 10000d → 1250 bytes | MRL+BQL 512 bits → 64 bytes | 93%+ 精度，1/20 存储 |
| 检索 | MemoryField 全量扫描 | 当前规模够用，规模上去后接 FAISS | 不过早优化 |

架构已准备好——Encoder Protocol 和 Projector Protocol 是可替换接口，换零件不换框架。

### 决策 2：三种关系在查询层解决，不在编码层

互补和干涉关系通过"多视角查询生成"实现：

- 一个 Skill（`multi-perspective-formulation`）接受用户意图，用 LLM 展开为 N 个视角
- 每个视角独立编码，独立在场中匹配
- 结果按视角标注后聚合呈现

这是一个单纯的 Skill，可以被 Skill Polisher 打磨优化。

### 决策 3：搁置的研究方向

以下方向存档到 `docs/research/`，不在当前迭代实施：

- GHRR 非交换 binding（复数域，不兼容 BSC，仅 KG 验证）
- 双曲空间多关系建模（无成熟二值化方案）
- Optuna 三目标 Pareto 前沿（需要先有评估框架）
- 完整 MLOps 基础设施（Hydra/W&B，团队规模不需要）

这些在真人数据验证后、或写论文时可以回来。

### 决策 4：实验 Skill 是第一优先级

在换眼睛之前，先建立衡量能力。

实验 Skill 不是"跑一次测试"，是一个**通用的、可复用的严谨实验能力**：
- 为任何架构决策设计可验证的实验
- 生成无结构性偏差、无观测偏差的测试样本
- 模拟真实环境（长短不一、噪声混杂）
- 产出可被外界挑战、检验、复现的证据
- 积累论文素材和设计日志

它要回答的核心问题不是"代码能不能跑"，而是"协议的价值能不能被证明"——泛化程度、成本效率、匹配质量。这些数据是给投资人、学术界、外部审查者看的。

---

## 执行顺序

```
① 实验 Skill（towow-lab）         — 建立衡量能力
② 换编码器 + 换压缩              — 站到 2024 技术水平
③ 多视角查询生成 Skill            — 解锁互补/干涉关系
④ 跑数据、看结果                 — 用实验 Skill 严谨验证
⑤ 沉淀设计日志 + 论文素材         — 贯穿全过程
```

---

## 原则对齐

| 原则 | 对齐方式 |
|------|---------|
| §0.2 协议层不可改，基础设施层可替换 | 编码器/投影器是基础设施层，直接换 |
| §6 Formulation 不对称设计 | 多视角生成 = 用户侧 formulation 透镜的正确位置 |
| §1 丰富→透镜→聚焦 | 一条意图通过多个透镜→多个聚焦的查询→多次匹配 |
| 代码保障 > Prompt 保障 | 实验 Skill 用代码验证效果，不凭直觉判断 |
| 工程验证优先于理论完美 | 先用最简单方案验证，不够用再升级 |

---

## 影响范围

| 影响 | 说明 |
|------|------|
| 新 Skill | `.claude/skills/towow-lab/SKILL.md` — 实验设计与验证 |
| 新 Skill | `multi-perspective-formulation` — 多视角查询生成 |
| 修改文件 | `encoder.py` — 替换编码模型 |
| 修改文件 | `projector.py` — 替换二值化方案 |
| 研究文档 | `docs/research/000-002` — 已沉淀，待后续更新 |
| 设计日志 | 贯穿执行过程，为论文积累素材 |

---

## 附：与研究结论的映射

| 研究结论 | 决策 |
|---------|------|
| 001: GHRR 与 BSC 不兼容 | → 搁置，查询层解决 |
| 001: 指令感知 embedding 可区分关系 | → 多视角生成 Skill 的理论基础 |
| 001: MRL+BQL 93%+ 精度 | → 替换 SimHash |
| 001: IN-OUT Dual Embedding 精准类比 | → 存档，写论文时有用 |
| 002: AIDE 树搜索最直接可用 | → 实验 Skill 可参考 |
| 002: 配对 bootstrap 小样本方法 | → 实验 Skill 内置 |
| 002: MLAgentBench 6 种失败模式 | → 实验 Skill 防护设计 |
| 000: Phase 2 零 LLM 匹配管道 | → 保持，匹配管道不引入 LLM |
