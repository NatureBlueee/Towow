# A1 — HDC 编码策略验证

> 创建日期：2026-02-07（2026-02-09 更新引用）
> 任务类型：协议核心 × 技术验证
> 优先级：Tier 1（#1）
> PRD 状态：已细化
> 关联任务：H4（最小验证实验，下游依赖 A1 的编码函数）、H5（超向量可视化，下游消费 A1 的产出）
>
> **2026-02-09 更新**：V1 已包含 HDC 编码的基线实现——`backend/towow/hdc/encoder.py`（MiniLM-L12-v2 + SimHash）可作为 A1 实验的起点和 baseline。A1 的价值仍在——验证编码质量、对比不同方法、找到最优策略。

---

## 这个任务在项目中的位置

通爻（ToWow）是一个 AI Agent 协作网络。它的核心理念是"响应范式"——不是像搜索引擎那样由用户主动检索，而是用户发出一个信号（需求），网络中相关的 Agent 自行判断"这跟我有没有关系"，然后主动响应。

要让 Agent"自行判断相关性"，需要一种高效的数学表示方法。通爻选择了**超维计算（Hyperdimensional Computing, HDC）**：把每个 Agent 的能力、经历、特长编码成一个 10,000 维的二进制向量，把每个需求也编码成同维度的向量，然后通过计算汉明距离来判断"这个 Agent 跟这个需求是否相关"。

**A1 就是验证这个编码过程的质量**——编码之后，语义信息还保留了多少？不同的编码方法效果差多大？这是整个系统的地基。

```
你在这里
    ↓
[A1: 编码质量验证] → [H4: 核心假设验证] → [H5: 可视化调试工具]
                   → [V1 共振检测实现]
```

---

## 为什么做这件事

通爻网络中，Agent 的存在形式就是 HDC 超向量。共振检测——判断一个需求信号是否与一个 Agent "对味"——依赖超向量之间的汉明距离。编码质量直接决定了共振检测的准确率。

**用日常语言说**：这就像调收音机的频率。如果编码（调频）不准，即使信号发出去了，该接收到的人接收不到（假阴性），不相干的人却接收到了（假阳性）。你的工作就是验证"调频"的精确度，找到最好的调频方法。

当前架构设计（Section 6.3.4）确定了三步编码流程：文本 → 嵌入向量 → SimHash → 二进制超向量。但**具体的编码策略**尚未通过实验验证——不同的编码方法会对最终效果有多大影响？这是需要量化回答的问题。

## 你要回答什么问题

**核心问题**：给定一段自然语言文本（如用户需求描述、Agent 能力描述），如何编码为 10,000 维二进制超向量，使得：
1. 语义相似的文本 → 汉明距离小（共振度高）
2. 语义不相关的文本 → 汉明距离接近 5,000（随机水平）
3. 编码过程足够快（< 10ms / 条）

**子问题**：
- SimHash vs MinHash vs Random Projection：哪种方法在"语义保持"上最好？
- 底层嵌入模型的选择：sentence-transformers（768 维）vs 更大的模型（1536 维）对最终共振检测质量的影响有多大？
- 维度数量（10,000 vs 5,000 vs 20,000）对区分度的影响？
- **bundle 操作**的质量：当把 5-10 个子向量 bundle 在一起（如技能1 + 技能2 + 经历1 + …），信息保留率如何？bundle 后还能准确共振吗？
- 中文 vs 英文文本的编码质量差异？（通爻是中文优先的系统）

## 我们提供什么

### 概念着陆（通爻术语 → A1 语境中的含义）

| 通爻术语 | 在 A1 中意味着 |
|---------|---------------|
| 投影（Projection） | 把一段文本（Agent 的能力描述）编码为超向量的过程。"丰富的东西通过透镜变成聚焦的东西"——这里的"丰富"是原始文本，"透镜"是编码器，"聚焦"是超向量 |
| 共振（Resonance） | 两个超向量的汉明距离足够小，表示语义上相关。你实验中的"语义保持率"直接决定了共振的准确性 |
| 签名（Signature） | 编码后的超向量就是一段信息的"签名"——它的振动特征。你在验证签名的保真度 |
| Bundle（捆束） | 多个超向量的逐位多数投票合并。Agent 画像 = bundle(技能1, 技能2, 经历1, ...)。你需要验证 bundle 后信息保留了多少 |
| 本质与实现分离 | 编码器接口（输入文本→输出超向量）是本质，具体用 SimHash 还是 MinHash 是实现。你的实验就是在找最好的实现 |

### 设计原则（与 A1 的关系）

| # | 原则 | 与 A1 的关系 |
|---|------|-------------|
| 0.8 | 投影是基本操作 | `project(profile_data, lens)` 中的 `project` 就是这个编码——A1 验证的是这个最基础操作的质量 |
| 0.3 | 复杂度目标 O(N+M) | 编码速度直接影响整体复杂度。如果编码太慢，每条消息的处理成本升高 |
| 0.2 | 本质与实现分离 | 编码器可插拔，接口稳定。你的实验结果会决定 V1 选哪个实现，但不改变接口 |

### 设计文档

| 文档 | 重点阅读 | 你能从中获得什么 |
|------|---------|----------------|
| `docs/ARCHITECTURE_DESIGN.md` Section 6.3.4 | HDC 三步编码流程 | 理解文本→嵌入→SimHash→超向量的完整 pipeline |
| `docs/ARCHITECTURE_DESIGN.md` Section 6.3.5 | 画像生成 | 理解 bundle 操作在系统中的角色 |
| `docs/ARCHITECTURE_DESIGN.md` Section 6.3.6 | 共振检测流程 | 理解你的编码产出会被怎么使用 |
| `docs/DESIGN_LOG_003_PROJECTION_AS_FUNCTION.md` | 投影即函数的核心洞察 | 理解"Agent 是投影函数的结果，不是有状态对象"——编码是这个函数的核心 |

### 工具和 Skill
- Arch Skill（`.claude/skills/arch/SKILL.md`）— 理解 HDC 在架构中的定位
- Dev Skill（`.claude/skills/towow-dev/SKILL.md`）— 工程实现指导

### 外部参考
- Kanerva, "Hyperdimensional Computing" (2009)
- Kleyko et al., "A Survey on Hyperdimensional Computing" (2023)
- Charikar, "Similarity Estimation Techniques from Rounding Algorithms" (SimHash, 2002)

### 已有代码（V1 基线实现）

| 资源 | 位置 | 用途 |
|------|------|------|
| **HDC Encoder** | `backend/towow/hdc/encoder.py` | V1 的 SimHash 编码实现（MiniLM-L12-v2），可直接作为实验基线 |
| **Resonance 检测** | `backend/towow/hdc/resonance.py` | 汉明距离 + k* 阈值机制的实现 |
| SDK 开发者指南 | `backend/docs/SDK_GUIDE.md` | HDC 编码在 SDK 中的定位说明 |

### 已有决策
- 架构文档已选定 SimHash 作为 V1 默认方案，V1 已实现（`towow/hdc/encoder.py`），但编码质量需要实验验证

## 子任务分解

### A1.1 — 调研候选编码方法
**描述**：阅读相关论文和文档，梳理 SimHash、MinHash、Random Projection 及其他可能的编码方法。每个方法记录：原理、优劣、适用场景。
**依赖**：无（起始任务）
**交付**：候选方法清单（每个方法 1 页总结）

### A1.2 — 准备测试数据集
**描述**：构造或收集用于评估编码质量的测试数据集。需包含：语义相似对、语义不相关对、边界案例（部分相关）。中英文各至少 50 对。
**依赖**：A1.1（了解方法后才知道需要什么测试数据）
**交付**：测试数据集（CSV/JSON）+ 数据说明文档

### A1.3 — 实现编码函数
**描述**：为至少 3 种编码方法实现 Python 编码函数。接口统一：`encode(text: str) -> BinaryVector`。同时实现 bundle 操作。
**依赖**：A1.1（知道要实现哪些方法）
**交付**：Python 代码 + 单元测试

### A1.4 — 运行实验对比
**描述**：用测试数据集评估各编码方法。对比维度：语义保持率（相关对距离 vs 不相关对距离）、编码速度、维度数量影响、bundle 后信息保留率、中英文差异。
**依赖**：A1.2 + A1.3
**交付**：实验结果表格 + 可视化图表

### A1.5 — 撰写实验报告 + 推荐方案
**描述**：整合实验结果，撰写报告。给出推荐方案及理由。标注已知局限和后续改进方向。
**依赖**：A1.4
**交付**：实验报告（Jupyter Notebook 或 Markdown，3000-5000 字）+ 1 页推荐方案

## 做完了是什么样

### 产出清单

1. **实验报告**（3000-5000 字）：完整的编码方法对比，有数据支撑
2. **推荐方案**（1 页）：清晰的"用什么方法、为什么"
3. **可复用代码**：编码函数 Python 实现 + 测试脚本，接口统一，可直接集成

### 三级质量标准

**做完了（基本合格）**：
- 至少对比 3 种编码方法
- 测试数据包含中英文各 50+ 对
- 有 bundle 操作的信息保留率数据
- 结论有量化支撑（不是"感觉 A 比 B 好"）
- 编码函数接口统一，代码可运行

**做得好（超出预期）**：
- 对比 5 种以上编码方法，或对某一方法有深入变体分析
- 测试数据覆盖了通爻实际场景（如"需求描述 vs Agent 能力描述"的匹配对）
- 发现了编码维度 / 嵌入模型 / 编码方法之间的交互效应
- bundle 操作有不同子向量数量（3/5/10/20）下的信息衰减曲线
- 代码有完善的文档和使用示例，其他贡献者能直接调用

**做得出色（产生额外价值）**：
- 提出了架构文档未考虑的新编码方案，并用数据证明其优势
- 发现了 HDC 编码在中文场景下的特殊问题或优势，对系统设计有启发
- 实验设计本身可作为通爻的标准 benchmark（后续其他编码方案的评估可直接复用）
- 写出了面向社区的科普文章：为什么通爻选择 HDC，编码质量如何影响"共振"

## 你必须遵守的

- 不需要关心通爻的业务逻辑——只关注"文本 → 超向量"的编码质量
- 编码器可插拔——统一接口，接受任何浮点嵌入向量作为输入
- 中文优先：测试数据必须包含中文文本
- HDC 是存在论承诺，不需要论证"要不要用 HDC"

## 你可以自己决定的

- 可以选择任何编码方法和嵌入模型
- 可以提出架构文档中没有的新方案
- 测试数据集可以自己构造
- 实验报告格式自由（Jupyter 或 Markdown）

## 对接方式

- 产出提交到：`research/A1_HDC_encoding/`
- 建议周期：2-3 周
- 后续依赖：H5（超向量可视化）需要 A1 的编码函数
