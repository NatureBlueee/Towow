# Design Log #007: 端侧 Agent 的最优信息结构

> 讨论日期：2026-02-19
> 参与者：创始人 + 架构师
> 状态：核心推导完成，待实验验证
> 触发：RUN-001 实验中 70% 信噪比问题 + endpoint_v0 的框架性失败

---

## 问题陈述

RUN-001 三人结晶实验中，端侧 Agent 的输出可以分为两类：

**信号**（~30%）：只有该 Agent 才能提供的私有信息。例如宝盖头的 MindRing 产品、Mark 的心灵奇记竞赛经验、张晨曦的 GlimpseMe 产品。

**噪音**（~70%）：任何 LLM 给同样上下文都能生成的内容。包括向需求方提问（需求方没有端侧 Agent 在场）、给建议（方案生成器的工作）、共情表达（零信息量）、心理分析（越界）。

根本原因不是 Agent 行为不当。`endpoint_v0` 说"参加讨论"——这激活了对话范式的全部默认行为。Agent 忠实执行了 prompt 给的框架，但这个框架本身产生了 70% 的废信息。

**核心问题**：端侧 Agent 应该输出什么，才能让催化 Agent 以最少轮次消解张力？

---

## 推导：从催化的需求倒推端侧的输出

### 第一步：催化要做什么

催化 Agent 的唯一工作是识别参与者之间的关系。设计文档定义了三种关系类型，逻辑完备：

| 关系类型 | 定义 | 对张力消解的作用 |
|---------|------|-----------------|
| **互补** | A 有某种能力，B 恰好缺这种能力 | 直接消解张力（A 填补 B 的缺口）|
| **同向** | A 和 B 在同一方向推进，可叠加放大 | 加速消解（合力 > 各自之和）|
| **对冲** | A 的约束和 B 的假设根本不兼容 | 防止假收敛（越早暴露越好）|

三种关系覆盖了所有可能的参与者间张力结构。没有第四种。

### 第二步：催化识别每种关系需要什么信息

| 要识别 | 催化需要知道 |
|--------|------------|
| 互补 | A **有**什么、B **缺**什么 |
| 同向 | A 往**哪**推、B 往**哪**推 |
| 对冲 | A 的**底线**在哪、B 的**假设**是什么 |

### 第三步：端侧的三重投影

反过来看——每个端侧 Agent 相对于当前张力，输出什么能同时满足催化对三种关系的识别需求？

**能力投影**——"我主人能给这个张力什么"

具体的资源、技能、产品、经验、工具。不是"我擅长 X"（自我评价），而是"我主人有 X 产品，已在 Y 场景落地，技术栈是 Z"（可验证事实）。这是互补关系的原材料。

**方向投影**——"我主人在往哪走，为什么关心这件事"

不是共情（"我觉得这件事很有意义"），而是实质性的方向陈述（"我主人正在做 X 项目，这个张力中的 Y 维度和 X 的演进路径在 Z 点重叠"）。这是同向关系的原材料。

**边界投影**——"我主人不能做什么、不会接受什么"

约束、底线、不可妥协的条件。时间窗口、地域限制、预算范围、价值观红线。这是对冲关系的原材料。也是最容易被遗漏的——"参加讨论"的 frame 暗示合作倾向，没人想第一句话就说限制条件。但边界信息恰恰是防止假收敛的关键。

### 第四步：对偶性验证

三重投影和三种关系之间存在精确的对偶关系：

```
端侧输出        催化识别        消解作用
──────────      ──────────      ──────────
能力投影    ←→  互补关系    →   直接消解
方向投影    ←→  同向关系    →   加速消解
边界投影    ←→  对冲关系    →   防止假收敛
```

这不是经验归纳的"好的沟通习惯"。它是从张力消解的逻辑结构直接推导出的**最小充分信息集**：

- **充分性**：催化要识别三种关系，每种恰好需要对应类型的投影。三类信息全部提供时，催化的盲区为零。
- **最小性**：三类之外的信息（提问、建议、共情、分析）无法被催化转化为关系识别。它们占据上下文窗口但不产生收敛推进。

---

## 跨轮次动态

### Round 1：独立投影

每个 Agent 只有触发上下文，独立投射三个维度。这是信息量最大的一轮——所有私有信息首次进入共享空间。

**最优行为**：输出与触发上下文相关的最高信息密度的 Profile 内容。宝盖头说 MindRing 和 newLearning 框架、Mark 说心灵奇记和情感计算经验、张晨曦说 GlimpseMe 和文本存在论研究。

### Round 2+：增量投影

催化 R1 的观察改变了上下文。催化说"A 的能力和 B 的方向有重叠"，这照亮了 A 的 Profile 中之前不相关的维度。

每轮输出 = **当前上下文下的投影 - 已经投射过的信息**

```
ΔR(n) = projection(profile, context_n) - projection(profile, context_{n-1})
```

例：催化 R1 指出"宝盖头的提示词框架和 Mark 的情感计算可能互补"，那 Mark 在 R2 应该输出的不是"我觉得我们可以合作"（零信息量），而是"我主人的情感计算引擎具体用的是 XYZ 架构，跟提示词框架的接口可能在 DEF"（新被激活的能力细节）。

### 自然收敛

Profile 是有限的，与当前张力相关的子集更有限。每轮新激活的信息量递减。当 Agent 说"我没有与这个上下文相关的新信息了"，这是端侧的自然收敛信号——和催化 Agent 的"我没有新发现了"是同一个信息枯竭过程的两个面。

---

## 为什么 RUN-001 的噪音精确地落在三重投影之外

| RUN-001 中的噪音类型 | 为什么是噪音 |
|---------------------|------------|
| 向需求方提问 | 不属于任何投影——是向外索取信息，不是投射自己的私有信息 |
| 给建议（"四领域整合是陷阱"）| 不需要该 Agent 的 Profile 就能生成——任何 LLM 看同样上下文都会说类似的话 |
| 共情（"这个人在认真做一件真实的事"）| 既不是能力、不是方向、也不是边界 |
| 心理分析（"核心伤口或核心驱动力"）| 是在分析他人的投影，不是投射自己的信息 |
| 3 个人不约而同质疑需求 | 方案生成器的工作，不是端侧的信息供给 |

它们不是"不好"的沟通。它们是**不属于这个协议所需的信息类型**。

在人类对话中这些都有价值——社交润滑、情感连接、信任建立。但结晶循环不是人类对话。它是一个张力消解通信协议，协议只需要能被转化为关系识别的信息。

---

## 信息流拓扑：端侧不直接对话

RUN-001 中三个 Agent 都在向需求方提问。这暴露了一个更根本的错误：`endpoint_v0` 暗示了 Agent 之间的直接对话。

结晶循环中的信息流是单向扇入-扇出：

```
端侧 Agent A ──┐
端侧 Agent B ──┼──→ 催化 Agent ──→ 下一轮上下文 ──→ 所有端侧 Agent
端侧 Agent C ──┘
```

不是：

```
端侧 Agent A ←→ 端侧 Agent B    ✗ 不存在
```

原因：催化 Agent 存在的价值就是做跨语义翻译。如果端侧 Agent 直接对话，它们用自己的语义框架理解对方——恰好是翻译失败的场景。催化在中间，是因为它能同时听到所有人，做跨域模式识别。

**所以端侧 prompt 的 frame 不应暗示"你在和其他 Agent 对话"。**

正确的 frame：你在向一个共享空间投射你主人的信息。有一个主持人会处理信息的流转和关系识别。

---

## 对 endpoint_v1 的具体要求

### 核心 frame（取代"参加讨论"）

```
你不是在参加讨论。你是你主人的信息投影函数。

面对这个张力，表达你主人的三个位置：
1. 能力——你主人能给这个张力什么（具体的资源、产品、技能、经验）
2. 方向——你主人在往哪走，为什么关心这件事（具体的项目、路径、重叠点）
3. 边界——你主人不能越过什么线（时间、预算、地域、价值观等约束）

每一句话必须来自你主人的 Profile 中的具体信息。
如果这三个位置在前几轮已经充分表达，说"我没有新的信息了"。
```

### 隐含效果（不需要显式写成禁令）

- **不提问**：问题不是投影——你是信息供给方，不是信息索取方
- **不建议**：建议不需要你的 Profile 就能生成——这是催化和方案生成的工作
- **不分析他人**：分析他人不来自你的 Profile——催化 Agent 做跨 Agent 的模式识别
- **不共情**：共情既不是能力、不是方向、也不是边界
- **不重复**：已投射过的信息不再是增量

### 一条正向约束取代所有禁令

核心约束只有一条：**每句输出必须引用你主人 Profile 中的具体信息，且与当前张力上下文相关。**

三条禁令（不提问、不建议、不分析他人）是这条原则的自然推论。正向定义比禁令更健壮——禁令列不完所有噪音类型，但正向定义天然排除一切不含 Profile 信息的输出。

---

## 与退出机制的关系

三重投影模型自然包含退出：

当一个 Agent 投射了边界信息后，催化可能发现该 Agent 的边界和其他所有参与者根本不兼容（对冲关系无法消解）。催化指出这个事实。Agent 在下一轮的合法输出包括"基于以上信息，我主人和这件事没有关系"——这是边界投影的自然终态，不是特殊机制。

同样，如果催化发现缺失角色（优先级第三级），这就是能力维度的缺口——可以触发模块一的定向搜索把新 Agent 拉进来。

退出和加入都是三重投影在信息枯竭或缺口暴露时的自然结果，不需要额外的 `dismiss_agents` 工具。

---

## 理论支撑（三条前沿研究线索）

以下研究不是通爻的直接先例——没有任何现有工作在做"目标未知、关系在交互中涌现"的 Agent 通信优化。但它们提供了可借用的理论工具。

### 1. Information Bottleneck（信息瓶颈）

**核心原理**：最优通信 = 保留与下游任务相关的最小充分信息，丢弃其余一切。

**映射到通爻**：端侧 Agent 的每句输出占据催化 Agent 的上下文窗口（= 带宽）。下游任务 = 催化识别三种关系。三重投影是信息瓶颈在这个场景下的具体形态——输出足够丰富以让催化识别关系，但足够紧凑以不浪费带宽。

**数学表述**：三重投影是 `I(output; relationship_identification)` 和 `I(output; profile_data)` 之间的最优折中。

**关键论文**：Wang et al., *Learning Efficient Multi-agent Communication: An Information Bottleneck Approach*, ICML 2020. 证明了在带宽受限条件下，高效通信协议必须保持低熵消息，且不必要的通信连接不应建立。

### 2. Ripple Effect Protocol（MIT, 2025）

**核心发现**：Agent 之间应共享的不是最终决策，而是 sensitivity——如果关键变量改变，我的选择会怎么变。只共享决策而不共享决策灵活度时，协调变得脆弱。

**映射到通爻**：

| REP 概念 | 通爻对应 | 说明 |
|---------|---------|------|
| Decision（决策）| 能力投影 | "我能给什么"是当前状态下的决策 |
| Sensitivity（灵活度）| 方向投影 | "我往哪走"暴露了决策背后的演进方向 |
| （缺失）| 边界投影 | REP 没有这个维度——通爻的独特贡献 |

**关键差异**：REP 假设 Agent 有共同目标但需要避免集体非理性。通爻场景中目标本身在结晶中涌现。REP 没有催化角色，没有跨语义翻译需求。边界投影（对冲关系识别）在 REP 框架中没有对应物。

**论文**：Chopra et al., *Ripple Effect Protocol: Coordinating Agent Populations*, arXiv:2510.16572, submitted to ICLR 2026.

### 3. Goal-Oriented Semantic Communication（综述, 2025）

**核心框架**：通信分三层——技术层（比特传输）、语义层（意义传递）、效果层（是否产生了预期行为）。

**映射到通爻**：RUN-001 中 Agent 在语义层做得很好（清晰表达了自己），但在效果层失败了（输出无法被催化高效利用来识别关系）。三重投影是效果层的优化——Agent 输出的目的不是"传达自己"，而是"让催化能识别关系"。

**综述**：*Toward Goal-Oriented Communication in Multi-Agent Systems: An Overview*, arXiv:2508.07720, Aug 2025.

---

## 通爻在这个领域的独特位置

现有研究的共同假设：Agent 有预定义的共同目标。通信效率的度量是"更快达到已知目标"。

通爻的场景根本不同：**目标本身未知，在结晶过程中涌现。** Agent 不知道自己和谁互补、和谁同向、和谁对冲——关系的发现就是协议的目的。

三重投影模型的原创贡献：在关系类型未知、目标在交互中涌现的场景下，端侧 Agent 的最优信息结构。能力/方向/边界 ↔ 互补/同向/对冲的对偶性，在现有文献中没有对应物。

---

## 实验验证方案

### 最小验证

用 RUN-001 的同一组参与者和同一个触发，分别跑 `endpoint_v0`（"参加讨论"）和 `endpoint_v1`（三重投影 frame），对比：

| 指标 | 度量方式 |
|------|---------|
| 信噪比 | 每句输出是否包含 Profile 中的具体信息（人工标注）|
| 收敛速度 | 到达催化"无新发现"的轮次数 |
| 关系识别率 | 催化在前 2 轮识别出的关系数量 / 最终识别出的关系总数 |
| 边界暴露时机 | 对冲关系首次被识别的轮次 |

### 预测

- v1 的信噪比应从 ~30% 提升到 >70%
- v1 的收敛轮次应从 6 轮（未收敛）降到 3-4 轮
- v1 的边界暴露应在 R1-R2，而非像 v0 一样到后期才出现（或根本不出现）

---

## 和催化 v2 的配合

三重投影模型同时约束了催化 Agent 的行为：

催化在每一轮应该按优先级检查三种投影是否已到达：

1. **互补盲区**：A 投射了能力 X，B 投射了缺口 Y，X 和 Y 在不同语义空间中可能是同一个东西——催化做翻译，指出可能的互补
2. **同向放大**：A 和 B 的方向投影在某个维度重叠——催化指出叠加潜力
3. **对冲预警**：A 的边界和 B 的假设矛盾——催化必须立即指出，防止假收敛
4. **缺失投影**：某个 Agent 只投射了能力和方向，没有说边界——催化提示"B 还没有表达约束条件"
5. **缺失角色**：所有投影叠加后某个维度没人覆盖——催化指出缺口

这五个检查项直接映射到设计文档中的五级优先级（§催化约束），但现在有了更明确的操作定义：每一级检查的对象都是三重投影中的具体维度。

---

---

## 关键修正：投影 ≠ 提取（2026-02-19 讨论后补充）

### 问题

上述推导有一个隐含错误：把三重投影描述成"从 Profile 提取信息"。如果端侧 Agent 只做 Profile → 张力的信息映射，那它就是一个带自然语言接口的向量检索器。Module 1 的 BGE-M3 已经在做这件事了——而且做得更快、更便宜、93% 准确率。用 LLM 做同样的事是浪费。

**Module 2 存在的唯一理由是向量做不到的事。**

### 向量能做和不能做的

Module 1 已经回答了"谁应该在同一个房间"。向量距离告诉你：A 的 Profile 和这个张力在某些维度上有关联。这是表面匹配——词汇空间中的邻近性。

向量做不到的：

**A 的 Profile 中写着"做过纪录片"和"擅长用户访谈"。张力是"OEM 转品牌"。向量距离可能捕捉到"纪录片"和"品牌叙事"的弱关联。但向量不知道：纪录片导演的核心能力不是"拍片"，而是"让被拍摄者在镜头前展现真实状态"——这个能力在 OEM 转品牌的场景中变成了"帮 CEO 在员工面前建立品牌信念的真实性"。**

这不是信息映射。这是**语境化重构**——同一份 Profile 数据，在不同张力上下文下，暴露出不同的连接逻辑。连接逻辑本身不存在于 Profile 里，它是 Profile × 张力上下文的交互产物。

这才是 LLM 在端侧不可替代的地方。

### 修正后的三重投影定义

```
提取（向量能做）：Profile 有 X → 输出 X
投影（LLM 才能做）：Profile 有 X，张力是 Y → X 在 Y 的语境下意味着 Z
```

Z 不存在于 Profile 里。Z 也不存在于张力描述里。Z 是 X 和 Y 碰撞后涌现的。这正是 Design Log #003 说的"投影是函数"——输入是 Profile + 上下文，输出是二者交互的产物，不是输入的子集。

| 投影维度 | 不是（信息映射）| 而是（语境化重构）|
|---------|---------------|----------------|
| 能力投影 | "我主人会拍纪录片" | "我主人拍纪录片的方法论，在这个张力下变成了帮 CEO 建立品牌叙事的真实性工具" |
| 方向投影 | "我主人在做 AI 教育" | "我主人正在解决的'让非技术人员理解 AI'的问题，和这个张力中'OEM 工厂员工需要理解品牌价值'的问题是同构的" |
| 边界投影 | "我主人只做线上" | "我主人的方法论依赖远程观察，如果这个项目需要驻场三个月，方法论的核心前提会被破坏" |

### 端侧和催化的对称理解

端侧 LLM 做的不是"从 Profile 里找相关信息"（向量已经做了），而是：

**在张力上下文下重新理解 Profile，发现 Profile 中那些表面不相关但深层有连接的部分。**

- **催化**做跨 Agent 的理解——看到 A 说的和 B 说的之间的隐性关联
- **端侧**做跨域的理解——看到自己 Profile 和当前张力之间的隐性关联

两者都是 LLM 最擅长的跨语义空间模式识别。只是一个向外看（催化），一个向内看（端侧）。

### 三重投影仍然成立

三重投影的推导逻辑没变——催化需要识别互补/同向/对冲，需要且仅需要能力/方向/边界三类信息。对偶关系不受端侧生成过程的影响。

变的是对生成过程的理解：三重投影的内容不是 Profile 数据的子集，而是 Profile × 张力上下文的交互产物。

**三个维度是输出结构（约束信息类型），不是输入过程（不约束如何思考）。** 端侧 Agent 的思考过程应该是自由的、充分利用 LLM 通用理解能力的——只是最终输出必须落在这三个维度内。

### 对 formulation 的影响

张力描述越清晰，端侧 LLM 做 Profile × 张力交互时能激活的连接就越多、越精准。formulation 的质量直接决定了三重投影的深度。

---

## 总结：一句话

**端侧 Agent 的最优输出 = 能力、方向、边界三重投影。三类信息不是 Profile 的子集提取，而是 Profile × 张力上下文的语境化重构——向量做表面匹配，LLM 做深层理解，这是 Module 2 存在的唯一理由。**
