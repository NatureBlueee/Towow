# 系统优化审查

**审查者立场**: 系统优化者 -- 从工程和产品可行性角度审查 EXP-009 结晶实验
**日期**: 2026-02-18
**审查范围**: ADR-014、DESIGN_LOG_006、SIM-001/002 全部输出、运行脚本、Prompt、WOWOK Machine 参考

---

## 结论摘要

EXP-009 成功验证了催化 prompt 的迭代方法论（v0 到 v1 的改进是实质性的），但作为产品的可行性验证，它距离真实场景还有 **五个结构性鸿沟**：(1) 合成 Profile 下 LLM 扮演的"端侧 Agent"本质上是同一个模型在做角色扮演，而非真实的异构 Agent，端侧同质化不是 prompt 问题而是架构问题；(2) 整个 POC 跳过了模块一到模块二的接缝，三人是手选的而非场发现的，参与者质量控制完全缺失；(3) 方案中的商业细节（70 万定价、40%/35%/25% 分配比例、3 个月时间表）全部是 LLM 编造的，没有任何锚定真实市场的机制；(4) 8 人 8 轮的规模下，催化 Agent 的上下文窗口将达到 100K+ token，成本从 $2-3 飙升到 $30-50/次，23 分钟延迟将膨胀到 1-2 小时；(5) POC 是完全同步的，而真实场景的异步性会从根本上瓦解"轮次"的概念。这些问题不是可以"后续迭代"的小问题，而是决定产品形态的架构级选择。

---

## 详细审查

### 1. POC 到产品的鸿沟

#### 1.1 合成 Profile 的致命局限

三个合成 Profile（Lina 1,967 字符、赵维 2,308 字符、Maya 2,859 字符）是精心设计的。它们有统一的结构（基本信息 / 我是谁 / 我真正擅长什么 / 经历 / 约束 / 我现在想要什么 / 最近在想的事 / 关于合作），每个人都在几乎相同的维度上做了完整表达。这解释了端侧同质化的根源之一。

但更深层的问题是：**设计者预埋了跨语义关联**（Ground Truth 1-4），然后用催化去"发现"这些关联。这是在测试催化的阅读理解能力，不是在测试催化发现真实跨语义连接的能力。真实场景中：

- 用户的 Profile 可能只有 200 字（"我是做外贸的，想找人做网站"）
- 用户的 Profile 可能没有跨语义关联（两个都是做 SEO 的，能力完全重叠）
- 用户可能不知道怎么写 Profile（"我不知道自己擅长什么"）
- Profile 中的信息可能过时（半年前写的，现在情况变了）

**产品影响**：如果 Profile 质量不够，催化做的"跨语义翻译"会退化为无意义的牵强附会。系统需要一个 Profile 质量下限检测机制，或者一个引导式 Profile 构建流程。ADR-014 和实验计划都没有涉及这个问题。

#### 1.2 触发事件从哪来

POC 的触发事件是一个精心构造的 CEO 案例，包含多层张力（品牌/组织/数字化），恰好与三个参与者的能力形成交叉关联。真实场景中：

- 触发事件可能极其简单："我想做一个小程序"
- 触发事件可能极其模糊："我想创业但不知道做什么"
- 触发事件可能不需要结晶：一个人就能解决

ADR-014 决策 2 说"用户主动触发"，但没有定义触发事件的最低质量标准。如果触发事件信息量不足，模块一发现的人可能与需求完全不匹配，模块二的结晶就建立在错误的参与者集合上。

#### 1.3 8 人规模的上下文窗口爆炸

POC 是 3 人 6 轮。来算一下 8 人 8 轮的催化 Agent 输入：

**第 1 轮催化输入**：
- 触发上下文：约 500 字符
- 8 个端侧回复：8 x 2,050 = 16,400 字符
- 总输入：约 17K 字符

**第 8 轮催化输入**：
- 触发上下文：500 字符
- 历史催化观察：7 轮 x 3,000 = 21,000 字符
- 8 个端侧回复：16,400 字符
- 总输入：约 38K 字符

加上 system prompt 和 Markdown 标记，第 8 轮的总上下文将超过 **50K 字符（约 15K-20K token）**。这在 Claude Sonnet 的窗口内，但有两个问题：

1. **注意力退化**：在 38K 字符的用户输入中，催化是否还能注意到第 2 轮某个人提的一个小约束？LLM 的注意力在长上下文中不是均匀的。
2. **成本非线性增长**：3 人 6 轮的输入 token 总计约 60K（每轮递增），8 人 8 轮约 300K token。按 Sonnet $3/M input, $15/M output 估算，仅催化部分的 API 成本就从 $0.5 涨到 $5-8，整个结晶（含端侧和方案生成）从 $2-3 涨到 $30-50。

#### 1.4 成本模型

假设每天 100 次结晶（产品初期可能只有 10 次，但需要为规模做准备）：

| 规模 | 每次成本 | 日成本 | 月成本 |
|------|---------|--------|--------|
| 3 人 6 轮 | $2-3 | $200-300 | $6K-9K |
| 5 人 6 轮 | $8-12 | $800-1,200 | $24K-36K |
| 8 人 8 轮 | $30-50 | $3,000-5,000 | $90K-150K |

"一次成功的结晶带来的协作价值远大于几十块钱的算力成本"（设计文档原话）在 3 人场景下成立，但在 8 人场景下需要重新评估。$30-50/次意味着每月 100 次的运营成本在 $90K-150K，而且这还没有算端侧 Agent 调用的成本（如果端侧也是 LLM）。

---

### 2. 端侧同质化

#### 2.1 数据呈现

评估报告承认："端侧输出长度和风格仍趋同（~2,050 chars/人/轮）"。从 round_3 和 round_6 的原始输出可以验证：

- **三个人都使用相同的 Markdown 格式**：`##` 标题 + 段落 + 列表
- **三个人的回复长度几乎相同**：每人每轮约 2,000-2,200 字符
- **三个人都在做"回应催化观察"而非"自主表达"**：几乎每个人的开头都是"看完主持人的观察，我需要说几件事"

#### 2.2 根因分析

评估报告将同质化归因于"合成 Profile 结构相似"和"Sonnet 模型的合作倾向"。但我认为更根本的原因是：**所有端侧 Agent 是同一个模型（Sonnet）在角色扮演**。

一个真实的 Lina（纪录片导演）可能会说："我说不清楚为什么，但我觉得这个 CEO 在演戏。我拍了十几年人，能分辨。" 而 LLM 扮演的 Lina 不会这样说，因为 LLM 没有真实的直觉和情绪，它只能根据 Profile 中的信息进行合理推断。

**这意味着催化做的"跨语义翻译"可能在翻译一种不存在的差异。** 三个"不同的人"实际上是同一个模型通过三个不同的 Profile 投射出来的三个影子。它们之间的"语义差异"是人工制造的，而非真实存在的。

#### 2.3 产品影响

真实产品中，端侧 Agent 可能是：
- SecondMe 级别的个性化模型（有真正不同的"认知风格"）
- 不同厂商的不同模型（GPT-4、Claude、Gemini 各自行为模式不同）
- 甚至是人类直接输入（最真实但最慢）

POC 用同一个模型做所有端侧，验证的是"同一个模型能不能扮演不同角色"，而不是"不同的端侧 Agent 能不能在催化下发现彼此的价值"。这两个问题本质不同。

**建议**：在 SIM-003 或后续实验中，至少用不同的模型（或不同的 temperature）来模拟端侧异构性。甚至可以让人类扮演其中一个端侧，观察"人 + LLM Agent"混合场景下催化的表现。

---

### 3. 方案质量

#### 3.1 SIM-001 vs SIM-002 方案对比

**SIM-001 方案**（v0 催化）：
- 核心框架：5 天测试周 + 小时级时间表（周一上午承诺测试、周一下午三人分头扫描、周一 17:00 对齐......）
- 定价：80-120 万（未细分）
- 特点：极其详细的操作流程，精确到每个时间段谁做什么。但大量内容来自催化的越界建议（"瞬间分享协议""描述对抗工作坊"都是催化设计的）。

**SIM-002 方案**（v1 催化）：
- 核心框架：3 个月分阶段（启动前准备 / 第一阶段 / 第二阶段 / 第三阶段）
- 定价：70 万联合服务包（Lina 40%/Maya 35%/赵维 25%）
- 特点：操作流程来自端侧自发涌现（信号系统、每日粗剪同步、版权分层），催化越界污染极少。

#### 3.2 如果我是那个 CEO，我选哪个？

**都不会选。原因如下：**

两个方案都有一个共同的致命缺陷：**它们读起来像是三个顾问在自嗨，而不是在解决 CEO 的问题。**

CEO 的问题是"从 OEM 代工转型品牌 DTC"。他需要的答案是：转型的第一步是什么？花多少钱？多久能看到结果？如果失败了损失多大？

SIM-001 方案给了一个 5 天测试周的详细操作手册，但没有回答"测试完了然后呢"。SIM-002 方案给了一个 3 个月诊断的框架，但 CEO 会问："我花 70 万让你们'诊断'三个月，诊断完了还要花多少钱才能真正开始转型？"

**两个方案都在描述"我们三个人怎么合作"，而不是"我们怎么帮 CEO 解决问题"。**

#### 3.3 定价的荒诞性

SIM-002 方案中的 70 万定价和 40%/35%/25% 分配比例看起来很具体，但来源是什么？

追溯到 round_3 的赵维回复："三个月诊断期：总价 60-80 万人民币。这个数字的逻辑：如果 CEO 单独请一个 OD 顾问至少 40-50 万，单独请品牌内容团队至少 30-40 万......"

**这个定价是 LLM 扮演的"赵维"基于合成 Profile 中没有的信息编造的。** 合成 Profile 中赵维的信息是"咨询按天收费"，Lina 的是"月收入 3-5 万"，Maya 的是"精品咨询公司合伙人"。没有任何人提供过"OD 顾问市场价 40-50 万"这个数据。

这意味着方案中的商业细节（定价、分配、时间表）全部是 LLM 的"合理推测"，没有被任何真实市场数据验证。在真实产品中，如果方案生成 Agent 输出了一个不靠谱的定价，参与者会立刻失去信任。

#### 3.4 方案比"三个人各自发邮件"好在哪？

这是最尖锐的问题。**结晶的核心价值主张是：通过催化对话，发现三个人各自看不到的协作可能性，产出一个比简单叠加更好的方案。**

证据支持这个主张吗？

**支持的部分**：
- SIM-002 中涌现了一些三个人各自不会想到的洞察（"鸡蛋问题"、"观测者效应"、"双地图并行"）
- 端侧之间从第 3 轮开始出现直接对话（"Lina，你怎么看？"），这是催化创造的信息传递渠道

**不支持的部分**：
- 最终方案中的大部分内容（每个人的角色、贡献、收益、成本、依赖）是可以从三个 Profile + 触发事件直接推导的，不需要 6 轮对话
- 一个优秀的人类主持人（比如一个经验丰富的项目经理）看完三个人的 Profile 后，30 分钟就能提出类似甚至更好的协作框架
- 6 轮对话 x 3 人 = 18 次端侧输出中，大量内容是重复的（同一个观点在不同轮次被不同角度重述）

**结论**：结晶的价值在于"过程中的发现"（意外洞察），而非"最终的方案"。但目前的产品设计将方案作为交付物，这可能是错误的价值锚定。

---

### 4. 模块一到模块二的接缝

#### 4.1 完全缺失的验证

POC 中三个参与者是手动选定的，完全跳过了模块一。ADR-014 决策 1 说"三视角并集 top-K 作为参与者列表"，但这个接口从未被测试过。

关键问题：

**模块一选错人怎么办？** 假设模块一为一个"想做小程序的餐饮老板"推荐了三个人：一个前端工程师（共振视角）、一个餐饮供应链专家（互补视角）、一个做 AI 教育的人（干涉视角）。前两个人合理，但第三个人跟需求几乎无关（干涉视角的本意是"意外关联"，但有时候意外就是纯噪声）。

如果催化开始运转，AI 教育的人会被迫在一个跟他无关的讨论中"找到自己的价值"。LLM 很擅长这种事（它总能找到某种牵强的联系），但这不是真正的价值发现，而是 LLM 的合理化倾向。

**结果**：催化产出的"跨语义翻译"可能包含大量虚假的关联，降低整个方案的可信度。

#### 4.2 参与者选择的质量控制

当前设计中，没有任何机制来判断"这些人是否真的应该在同一个房间里"。模块一输出的是向量距离排序，模块二直接消费这个排序。中间没有：

- **参与者意愿确认**：被推荐的人是否愿意参与？
- **参与者资质验证**：Profile 中声称的能力是否真实？
- **集合质量检测**：这组人是否有足够的异质性？还是说选了三个都是做营销的？
- **人数适配**：这个触发事件是否真的需要 5 个人？还是 2 个人就够了？

#### 4.3 干涉视角的风险

ADR-014 特别强调"干涉视角权重不低于其他两个"。设计意图是好的（意外关联最有催化价值），但在产品中，如果干涉视角推荐了一个完全不相关的人，用户的体验会非常差。

这是一个需要用数据来回答的问题：干涉视角推荐的参与者中，有多少比例在结晶后被证明确实有价值？如果这个比例低于 30%，干涉视角的高权重就是在浪费所有人的时间。

---

### 5. 收敛产物

#### 5.1 自然语言方案的局限

当前方案生成器产出的是一个 Markdown 格式的自然语言方案。SIM-002 的方案长度为 4,218 字符，包含：
- 协作全景（1 段）
- 各参与者方案（3 个，每个约 800-1000 字符，含角色/贡献/收益/成本/依赖）
- 协作顺序与节点（分阶段描述）

这个方案作为"人类可读的协作提案"质量尚可，但存在几个结构性问题：

1. **不可执行**：方案中说"每两周给 CEO 一次 30 分钟的汇报"，但没有说谁负责约时间、如果 CEO 取消怎么办、汇报的具体模板是什么。从"方案"到"行动"之间还有一大段路。
2. **不可验证**：方案说"Lina 拍摄 2-3 个月"，但没有定义"拍完了"的标准。什么算完成？谁来判断？
3. **不可修改**：方案是一个整体，如果 CEO 说"时间太长了，能不能压缩到 1 个月"，方案生成器不会自动调整其他参数（比如减少拍摄范围、降低诊断深度）。

#### 5.2 自然语言到 WOWOK Machine JSON 的信息丢失

WOWOK Machine JSON 的核心结构是 nodes（工作流阶段）+ pairs（转换条件）+ forwards（角色权限操作）+ threshold/weight（验收逻辑）。

从 SIM-002 方案中抽取可映射的信息：

| 方案内容 | 是否可映射到 JSON | 丢失的信息 |
|---------|-----------------|-----------|
| 阶段 0/1/2/3 → nodes | 是 | 阶段之间的软依赖（"如果 CEO 中途叫停"） |
| Lina/Maya/赵维 → namedOperator | 是 | 角色的弹性（"如果我发现工作量超预期"） |
| "Lina 完成前三周拍摄 → Maya 开始干预" → pairs | 部分可映射 | "前三周"是约数，不是硬时间线 |
| "CEO + 三个关键中层看汇报" → threshold | 理论上可映射 | 谁是"关键中层"需要运行时确定 |
| "版权归企业"/"如果 CEO 中途叫停" → Guard | 非常勉强 | 这些条件需要法律文本级别的精确定义 |

**核心矛盾**：WOWOK Machine JSON 是为确定性工作流设计的（工厂流水线、审批流程），而结晶产出的协作方案充满了模糊性和条件性。强行将自然语言方案转换为 JSON，要么丢失大量关键信息（条件、弹性、例外情况），要么生成一个极其复杂的 Guard 网络（每个"如果...就..."都变成一个 Guard）。

SIM-002 方案中的这些表述是无法被 JSON 表达的：
- "如果 CEO 中途叫停，三个月的时间投入可能无法被其他客户填补"
- "版权归企业，但 Lina 可以在转型成功后 1-2 年制作外部版本"
- "联合服务包内的工作量分配是三个人自己协调的事，CEO 不需要知道"
- "如果某天的'意外观察'互相矛盾很严重，30 分钟不够"

这些都是自然语言才能承载的微妙关系。JSON 版本必然是简化版，简化的部分恰恰是协作中最容易出问题的部分。

#### 5.3 方案生成器的"有据可查"原则被违反了吗

方案生成器 prompt v0 强调"所有陈述必须有据可查"。但 SIM-002 方案中：
- "70 万"这个数字来源于赵维在对话中的提议，赵维的提议来源于 LLM 的"合理推测"
- "40%/35%/25%"的分配比例同上
- "2-3 个月"的时间表是端侧自己说的，没有任何外部验证

从形式上看，方案生成器确实在结晶记录中找到了这些数据的"出处"。但"出处"本身就是 LLM 编造的。这是一个递归问题：LLM 在对话中编造了数据，方案生成器在记录中"发现"了这些数据，然后将其作为"有据可查"的方案输出。

---

### 6. 成本与时延

#### 6.1 当前 POC 的资源消耗

从实验记录中提取精确数据：

| 维度 | SIM-002 |
|------|---------|
| 总运行时间 | ~23 分钟 |
| 总 API 调用 | 25 次（6 轮 x 4 + 方案） |
| 总输出字符 | ~145K chars |
| API 成本 | ~$2-3 |

#### 6.2 8 人 8 轮的估算

假设：
- 端侧回复长度不变（~2,050 chars/人/轮）
- 催化输出长度扩展到 4,500 chars/轮（8 人需要更多分析）
- 方案生成输出扩展到 8,000 chars（8 个参与者）

**API 调用次数**：8 轮 x (8 端侧 + 1 催化) + 1 方案 = 73 次

**催化 Agent 输入 token 估算**（逐轮累积）：

| 轮次 | 输入内容 | 估算字符 | 估算 token |
|------|---------|---------|-----------|
| R1 | trigger(500) + 8 responses(16,400) | ~17K | ~5K |
| R2 | trigger + R1 catalyst(4,500) + 8 responses | ~22K | ~7K |
| R4 | trigger + 3x catalyst + 8 responses | ~31K | ~10K |
| R8 | trigger + 7x catalyst + 8 responses | ~49K | ~16K |

催化 Agent 的总输入 token（8 轮累计）：约 80K token
催化 Agent 的总输出 token（8 轮）：约 12K token
端侧 Agent 的总输入 token（8 人 x 8 轮，每轮含 Profile + trigger + 催化观察）：约 320K token
端侧 Agent 的总输出 token：约 50K token
方案生成：输入约 120K token（含全部 transcript + 8 个 Profile），输出约 3K token

**Sonnet 定价估算**（$3/M input, $15/M output）：

| 组件 | 输入成本 | 输出成本 | 小计 |
|------|---------|---------|------|
| 催化 | $0.24 | $0.18 | $0.42 |
| 端侧 | $0.96 | $0.75 | $1.71 |
| 方案 | $0.36 | $0.045 | $0.41 |
| **总计** | **$1.56** | **$0.98** | **$2.54** |

修正：上述估算偏低，因为没有计入 system prompt 的 token。加上 system prompt（催化的 system prompt 约 1K token x 8 轮 = 8K），实际成本约 $3-5。

**但如果催化模型从 Sonnet 升级到 Opus**（设计文档说"用最好的"）：
Opus 定价 $15/M input, $75/M output：

| 组件 | Sonnet 成本 | Opus 催化成本 | 混合成本 |
|------|-----------|-------------|---------|
| 催化 | $0.42 | $1.20 + $0.90 = $2.10 | $2.10 |
| 端侧 | $1.71 | $1.71 (仍用 Sonnet) | $1.71 |
| 方案 | $0.41 | $0.41 (仍用 Sonnet) | $0.41 |
| **总计** | **$2.54** | | **$4.22** |

结论：即使 8 人 8 轮，如果端侧仍用 Sonnet、催化用 Opus，每次结晶成本约 $4-5，可控。但如果所有组件都用 Opus（未来可能的方向），成本将飙升到 $15-25/次。

#### 6.3 时延分析

SIM-002 的 23 分钟 = 6 轮 x (~220s/轮) + 方案生成。
每轮约 220 秒 = 3 个端侧调用（串行，含 0.5s 间隔）+ 1 个催化调用。

端侧调用分析：
- 每个端侧调用约 30-40 秒（输入 ~5K token，输出 ~700 token）
- 3 个端侧串行 = ~110 秒
- 催化调用约 60-80 秒（输入递增，输出 ~1K token）

8 人场景：
- 8 个端侧串行 = ~300 秒
- 催化（输入更大）= ~90-120 秒
- 每轮 ~420 秒 = 7 分钟
- 8 轮 = 56 分钟 + 方案生成 ~5 分钟 = **约 60 分钟**

**关键优化点**：端侧调用是可以并行的。代码中端侧调用是串行的（循环 + 0.5s sleep），但从协议角度看，同一轮的端侧回复互不依赖，完全可以并发调用。如果并行化：

- 8 个端侧并行 = ~40 秒（最慢的那个）
- 催化 = ~120 秒
- 每轮 ~160 秒
- 8 轮 = ~21 分钟 + 方案 = **约 25 分钟**

这个时延在"异步协作"场景中完全可接受（用户发起，25 分钟后收到通知），但在"实时体验"场景中仍然太长。

**脚本中的串行调用是一个低垂的工程优化果实**。`run_sim.py` 第 271-289 行的 for 循环应该改为并发调用。

---

### 7. 异步问题

#### 7.1 POC 的同步假设

POC 中的每一轮是严格同步的：所有端侧 Agent 同时收到输入，同时产出回复，然后催化同时读取所有回复。这在 LLM 模拟中自然成立，但在真实产品中完全不成立。

真实场景：
- Maya 在新加坡，早上 9 点看到通知，10 分钟内回复了
- 赵维在杭州，下午 3 点才打开手机，写了一段很长的回复
- Lina 在拍摄现场，当天没有回复，第二天早上补了一条很短的消息

#### 7.2 "轮次"的概念崩塌

在同步模式下，"轮次"是天然的节奏单位。催化等所有人回复后再输出观察。但在异步模式下：

1. **等待问题**：催化要等最慢的那个人吗？如果一个人 24 小时不回复，其他 7 个人的时间都被浪费了。
2. **部分信息问题**：如果催化不等，它可能在只有 5/8 人回复的情况下就要做观察。观察中对缺席者说"没有信息"，缺席者看到后可能感到被排斥。
3. **节奏不一致问题**：快的人可能已经在"第 3 轮"了，慢的人还在"第 1 轮"。如果催化观察引用了第 2 轮的讨论，第 1 轮的人看不懂。

#### 7.3 可能的架构方案

设计文档和 ADR-014 都没有讨论异步问题。但从系统设计角度看，至少有三种方案：

**方案 A：固定时间窗口**
- 每轮有一个截止时间（比如 24 小时）
- 截止时间前回复的人的内容进入本轮
- 未回复的人跳过本轮，下轮收到之前的催化观察
- 问题：时间窗口多长？太短则参与者焦虑，太长则结晶拖延数天

**方案 B：事件驱动的弹性轮次**
- 不再有固定的"轮次"
- 每当有新的端侧回复到达，催化就做一次增量观察
- 观察的内容是"自上次观察以来的新信息"
- 问题：催化调用频率不可控，成本和质量都不确定

**方案 C：混合模式**
- 第一轮是异步的（给所有人 48 小时回复）
- 第一轮收集到足够回复后，催化产出第一次观察
- 后续轮次给更短的时间窗口（12 小时）
- 如果某人持续不回复，从结晶中移除
- 问题：移除参与者会改变催化的分析基础

**无论选哪个方案，都需要回答一个根本性问题：异步场景下催化的上下文管理如何设计？** 如果催化每次只能看到部分回复，它的"不遗漏任何人"约束就无法满足。如果催化等待所有人回复，"连续两轮无新发现"的收敛条件可能需要等一周才能验证。

---

## 优先级排序的改进建议

| 优先级 | 问题 | 影响 | 建议方案 |
|--------|------|------|---------|
| **P0** | 异步架构缺失 | 产品不可用 | 在 ADR-015 中明确异步策略。建议先实现方案 C（混合模式），第一轮 48h + 后续 12h + 移除机制。这是一个架构级决策，影响催化 prompt、收敛逻辑、前端 UX 的所有设计。 |
| **P0** | 模块一到模块二的接缝未验证 | 参与者集合可能错误 | 设计一个端到端测试：从模块一的真实场发现结果中取 top-K，送入模块二结晶，评估"场发现推荐的人是否真的适合在一起"。需要至少 50 个 Profile 的数据集。 |
| **P1** | 端侧同质化 | 催化的翻译可能是虚假的 | (1) 下一次模拟中用不同模型做不同端侧；(2) 真实 Profile 收集后立即替换合成 Profile 重跑；(3) 端侧 prompt 中增加"你不需要同意主持人的观察"和"你可以用任何你习惯的方式表达"。 |
| **P1** | 方案中的商业细节无锚定 | 用户信任风险 | 方案生成器 prompt 中增加约束："不要编造定价数字。如果参与者在对话中提出了具体数字，标注为'参与者提议，未经验证'。如果没有人提数字，明确写'定价需要参与者线下协商'。" |
| **P1** | 端侧调用串行化 | 时延不必要地翻倍 | 将 `run_sim.py` 中的端侧调用改为并发（`asyncio.gather` 或 `concurrent.futures`）。这是零风险的性能优化。 |
| **P2** | max_tokens 截断收敛判断 | 收敛机制无法运转 | 提升到 4500 token，同时在 prompt 中将收敛判断移到最前面（"先写收敛判断，再写翻译和分析"）。已在评估报告中识别，需要在 v1.1 中执行。 |
| **P2** | 8 人规模的催化注意力质量 | 可能遗漏关键信息 | 需要在 Phase 5（规模测试）中验证。如果 8 人场景下催化开始遗漏参与者，考虑分组策略（4+4 → 催化分别观察 → 合并）。 |
| **P2** | WOWOK Machine JSON 映射的信息丢失 | 链上合约不完整 | 接受信息丢失是不可避免的。JSON 版本只覆盖"确定性的工作流步骤"，模糊的条件性关系保留在自然语言版本中。两个版本并行存在，不试图用 JSON 表达所有内容。 |
| **P3** | 成本模型未建立 | 规模化时可能亏损 | 建立成本模型：参与者人数 x 轮次 x 模型单价 = 每次结晶成本。根据成本模型决定默认的人数上限和轮次上限。考虑分层定价（基础版 3 人 4 轮 Sonnet，高级版 8 人 8 轮 Opus）。 |
| **P3** | 触发事件质量控制 | 模块一推荐无关的人 | 在结晶启动前增加一个"触发事件质量检查"步骤：LLM 快速评估触发事件是否包含足够的信息来支持多人协作（vs 单人就能解决）。如果信息不足，提示用户补充。 |
| **P3** | 翻译固定 4 条/轮 | 轻微的质量问题 | 在 v1.1 prompt 中加"质量优先于数量"。这是已知问题，修复成本很低。 |

---

*审查基于 EXP-009 全部实验材料、运行脚本、输出记录和设计文档。所有引用的数据和原文可在附录 A 的文件索引中查证。*
